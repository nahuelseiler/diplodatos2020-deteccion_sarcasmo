{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "from spacy.lang.en import English\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import textacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos por cargar los datasets con los que vamos a trabajar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si utilizamos el encoding ISO-8859-1 el lector de pandas atumaticamente interpretara a las strings del documento como\n",
    "#elementos spacy (tokens, docs). El problema es que no esta tokenizadas por palabras.\n",
    "\n",
    "df1 = pd.read_csv('../datasets/GEN-sarc-notsarc (1).csv') #encoding='ISO-8859-1')\n",
    "df2 = pd.read_csv('../datasets/HYP-sarc-notsarc.csv') #encoding='ISO-8859-1')\n",
    "df3 = pd.read_csv('../datasets/RQ-sarc-notsarc.csv') #encoding='ISO-8859-1')\n",
    "\n",
    "#df1 = pd.read_csv('C:\\\\Users\\\\rubin\\\\Desktop\\\\DiploDatos\\\\Ment-Sarcasmo\\\\sarcasm_v2\\\\GEN-sarc-notsarc.csv')\n",
    "#df2 = pd.read_csv('C:\\\\Users\\\\rubin\\\\Desktop\\\\DiploDatos\\\\Ment-Sarcasmo\\\\sarcasm_v2\\\\HYP-sarc-notsarc.csv')\n",
    "#df3 = pd.read_csv('C:\\\\Users\\\\rubin\\\\Desktop\\\\DiploDatos\\\\Ment-Sarcasmo\\\\sarcasm_v2\\\\RQ-sarc-notsarc.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos a tokenizar. Para esto usaremos una función que armamos con un tokenizador de la librería spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con esta funcion podemos tokenizar una pd series y luego reemplazarla en el df.\n",
    "def column_tokenizer(dataframe, column_name='', sw_lemma=True):\n",
    "    '''Devuelve una lista tokenizada y el lower case de los documentos\n",
    "    de la columna de un pandas df, como objetos doc.spacy y token.spacy. Si \n",
    "    sw_lemma=True ademas lematiza y remueve stopwords'''\n",
    "    if sw_lemma:\n",
    "        nlp = spacy.load('en_core_web_sm', disable = ['parser'],) #'ner','tagger'])        \n",
    "        all_stopwords = nlp.Defaults.stop_words\n",
    "        df_tk_txt = []\n",
    "        for row in dataframe[column_name]:\n",
    "            df_tk_txt.append(nlp(row.lower()))\n",
    "        df_lemmatized = []\n",
    "        for doc in df_tk_txt:\n",
    "            df_lemmatized.append(nlp(\" \".join([token.lemma_ for token in doc if token not in all_stopwords and token.is_punct == False])))\n",
    "        return df_lemmatized\n",
    "    else:    \n",
    "        nlp = English()\n",
    "        tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "        df_tk_txt = []\n",
    "        for row in dataframe[column_name]:\n",
    "            df_tk_txt.append(tokenizer(row.lower(), min_freq=0))\n",
    "        return df_tk_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos las columnas text de los datasets, tokenizando, llevando a lower case, lemmatizando y removiendo stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_nm = df1\n",
    "df2_nm = df2\n",
    "df3_nm = df3\n",
    "df1_nm['text'] = column_tokenizer(df1_nm, column_name= 'text', sw_lemma=True)\n",
    "df2_nm['text'] = column_tokenizer(df2_nm, column_name= 'text', sw_lemma=True)\n",
    "df3_nm['text'] = column_tokenizer(df3_nm, column_name= 'text', sw_lemma=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora buscamos la forma de calcular el **tf idf** (spacy no tiene un metodo o funcion para calcularla, asi que debemos hechar mano a alguna que otra libreria). En este caso utilizamos la biblioteca sklearn, que posee muy buena sinergía con pandas. Aprovechando que los datos están estructurados en un csv, echamos mano del modelo count vectorizer. Esto implica una desviación del pipeline, dado que sklearn no trabaja con objetos de la librería spacy. Debido a esto (y al costo computacional) aplicaremos tfidf a un solo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>005</th>\n",
       "      <th>01</th>\n",
       "      <th>018</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>035</th>\n",
       "      <th>03angi</th>\n",
       "      <th>0422</th>\n",
       "      <th>...</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoos</th>\n",
       "      <th>zorach</th>\n",
       "      <th>zorba</th>\n",
       "      <th>zpq0120756920001</th>\n",
       "      <th>zsu</th>\n",
       "      <th>zsu2357</th>\n",
       "      <th>zwingli</th>\n",
       "      <th>zygote</th>\n",
       "      <th>zygotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6520 rows × 17596 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  005   01  018   02   03  035  03angi  0422  ...  zoo  zoos  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   0.0  ...  0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   0.0  ...  0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   0.0  ...  0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   0.0  ...  0.0   0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   0.0  ...  0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...     ...   ...  ...  ...   ...   \n",
       "6515  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   0.0  ...  0.0   0.0   \n",
       "6516  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   0.0  ...  0.0   0.0   \n",
       "6517  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   0.0  ...  0.0   0.0   \n",
       "6518  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   0.0  ...  0.0   0.0   \n",
       "6519  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   0.0  ...  0.0   0.0   \n",
       "\n",
       "      zorach  zorba  zpq0120756920001  zsu  zsu2357  zwingli  zygote  zygotes  \n",
       "0        0.0    0.0               0.0  0.0      0.0      0.0     0.0      0.0  \n",
       "1        0.0    0.0               0.0  0.0      0.0      0.0     0.0      0.0  \n",
       "2        0.0    0.0               0.0  0.0      0.0      0.0     0.0      0.0  \n",
       "3        0.0    0.0               0.0  0.0      0.0      0.0     0.0      0.0  \n",
       "4        0.0    0.0               0.0  0.0      0.0      0.0     0.0      0.0  \n",
       "...      ...    ...               ...  ...      ...      ...     ...      ...  \n",
       "6515     0.0    0.0               0.0  0.0      0.0      0.0     0.0      0.0  \n",
       "6516     0.0    0.0               0.0  0.0      0.0      0.0     0.0      0.0  \n",
       "6517     0.0    0.0               0.0  0.0      0.0      0.0     0.0      0.0  \n",
       "6518     0.0    0.0               0.0  0.0      0.0      0.0     0.0      0.0  \n",
       "6519     0.0    0.0               0.0  0.0      0.0      0.0     0.0      0.0  \n",
       "\n",
       "[6520 rows x 17596 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_tfidf = pd.read_csv('../datasets/GEN-sarc-notsarc (1).csv')\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df1_tfidf['text'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df_tdif = pd.DataFrame(denselist, columns=feature_names)\n",
    "df_tdif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto podemos hacer varias visualizaciones sobre la informaciones. Por ejemplo, podemos visualizar la distribución de los valores de tfidf de una feature a lo largo de todos los documentos. Mostramos cómo ejemplo la palabra \"what\". Vemos que en la mayoría de los documentos tiene un valor de 0, indicando que no ocurre, mientras que en aquellos que ocure, su tf-idf no es mayor a 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x217b3e6aa90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEGCAYAAAB8Ys7jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXcklEQVR4nO3de3Bc5XnH8e+zd0kr2ZYlX7ANBkK4hTiAU2gCCQklBdIE0oZp2lw8KVOaaXNtMwltZ5p0OpnJ9JakSVqGIenQSdqUkrSQCyHElAEmgcQEDBhDzCW1jW1JNtbNllba3ad/7FlblmXrSNqV/B7/PjOe3T179uzzSuPfefWe855j7o6IiIQntdAFiIjI7CjARUQCpQAXEQmUAlxEJFAKcBGRQGXm88u6urp87dq18/mVIiLBe+yxx/a6e/fk5fMa4GvXrmXTpk3z+ZUiIsEzs/+barmGUEREAqUAFxEJlAJcRCRQCnARkUApwEVEAqUAFxEJlAJcRCRQCnARkUApwEVEAjWvMzEXyr8/uv2oZb9/yakLUImISOOoBy4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEqhYAW5mnzCzLWb2tJn9h5kVzKzTzO4zs23R45JmFysiIodNG+Bmtgr4KLDe3V8DpIH3ADcDG939LGBj9FpEROZJ3CGUDNBiZhmgFdgFXAfcHr1/O3B948sTEZFjmTbA3f1l4O+B7cBuYMDdfwQsd/fd0Tq7gWVTfd7MbjKzTWa2qa+vr3GVi4ic5OIMoSyh1ts+HTgFaDOz98X9Ane/1d3Xu/v67u7u2VcqIiJHiDOE8hvAS+7e5+7jwHeANwA9ZrYSIHrsbV6ZIiIyWZwA3w5camatZmbAlcBW4G5gQ7TOBuCu5pQoIiJTyUy3grs/amZ3Ar8AysDjwK1AEbjDzG6kFvI3NLNQERE50rQBDuDunwE+M2lxiVpvXEREFoBmYoqIBEoBLiISKAW4iEigFOAiIoFSgIuIBEoBLiISKAW4iEigFOAiIoFSgIuIBEoBLiISKAW4iEigFOAiIoFSgIuIBEoBLiISKAW4iEigFOAiIoFSgIuIBEoBLiISKAW4iEigFOAiIoFSgIuIBEoBLiISKAW4iEigFOAiIoFSgIuIBEoBLiISKAW4iEigFOAiIoFSgIuIBEoBLiISKAW4iEigFOAiIoFSgIuIBEoBLiISKAW4iEigYgW4mS02szvN7Fkz22pmv25mnWZ2n5ltix6XNLtYERE5LG4P/EvAD939HGAdsBW4Gdjo7mcBG6PXIiIyT6YNcDPrAN4EfA3A3cfcvR+4Drg9Wu124PpmFSkiIkeL0wM/A+gD/tXMHjez28ysDVju7rsBosdlU33YzG4ys01mtqmvr69hhYuInOziBHgGuAj4F3e/EDjADIZL3P1Wd1/v7uu7u7tnWaaIiEwWJ8B3Ajvd/dHo9Z3UAr3HzFYCRI+9zSlRRESmMm2Au/seYIeZnR0tuhJ4Brgb2BAt2wDc1ZQKRURkSpmY630E+KaZ5YAXgQ9SC/87zOxGYDtwQ3NKFBGRqcQKcHd/Alg/xVtXNrYcERGJSzMxRUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFCJD/CDY2V++PRuRsYqC12KiEhDxQ5wM0ub2eNm9r3odaeZ3Wdm26LHJc0rc/Z+8NQeHty2l+d6hha6FBGRhppJD/xjwNYJr28GNrr7WcDG6PUJ575n9gDwyoHSAlciItJYsQLczFYDbwdum7D4OuD26PntwPWNLW3uRscrPPjLvQDsGx5b4GpERBorbg/8i8CngOqEZcvdfTdA9Lhsqg+a2U1mtsnMNvX19c2p2Jl6eNteRsYr5NIpXjmgABeRZJk2wM3st4Bed39sNl/g7re6+3p3X9/d3T2bTczafc/00J7PcP4pHexTgItIwmRirPNG4J1mdi1QADrM7BtAj5mtdPfdZrYS6G1moTNVqTobn+3hzWd3M16u8viOfkrlCvlMeqFLExFpiGl74O7+5+6+2t3XAu8B7nf39wF3Axui1TYAdzWtyll4Ysd+9g6P8bbzV9BZzANoGEVEEmUu54F/HrjKzLYBV0WvTxg/eqaHbNq44uxuOttygA5kikiyxBlCOcTdHwAeiJ7vA65sfEmNcd+WHi49YykdhSxLowBXD1xEkiSRMzFf6Bvmxb0HeNt5ywEoZNO05tI6kCkiiZLIAN+6exCA9Ws7Dy1b2pbTZB4RSZREBnjfUC2ol3cUDi1bWsyrBy4iiZLYAM+kjMUt2UPLOttyDBwcp1ypHueTIiLhSGyAd7fnSaXs0LKlbTkc2H9wfOEKExFpoGQG+HAtwCfqPHQmisbBRSQZEhngvYMluotHBvjS6LXGwUUkKRIZ4FP1wNtyaXKZlAJcRBIjcQFeqTr7hkssmxTgZlY7lVCzMUUkIRIX4K8cGKPqHNUDh9o4uHrgIpIUiQvw3qFRYOoAX9qWZ/+BMaru812WiEjDJS7A65N4pg7wHBV3BkZ0KqGIhC+5AV4sHPVeZ1FXJRSR5EhegA8fuwe+pLUW4P0HFeAiEr7EBXjvYIn2fIaW3NF33mkv1K6eO1wqz3dZIiINl7gAn+oc8LpsOkU+k2JIAS4iCZC8AB8q0XWMAAco5jMMjyrARSR8iQvwvUPH7oEDFAsZDaGISCIkLsD7ho6ehTmReuAikhSJCvCRsQpDpfLxe+B59cBFJBkSFeCHzwE/doC3FzKMjFcolSvzVZaISFMkK8CHjz2Nvq6Yr92lR5N5RCR0yQrwqAe+rP3oWZh1xXztXPC9w7qxg4iELVEB3nuc66DUFQsKcBFJhkQFeN9QiZQdvn3aVNrrPfAhDaGISNgSF+BLi3nSE25mPFm9B96nHriIBC5xAX68M1Dg8HT6+ni5iEiokhXgwyWWdRw/wKF2IFNj4CISukQF+FR3o59KsaAAF5HwJSbAq1Vn73GuRDhRrQeug5giErbEBHj/yDjlqscOcI2Bi0joEhPgcSbx1BULGQZGxhkrV5tdlohI0yQmwI93N/rJ6rMx9x1QL1xEwpWYAK/3wLuKx57EU9ceXQ9Fk3lEJGSJCfA9g7Ue+IpF8YZQQNPpRSRs0wa4ma0xs/81s61mtsXMPhYt7zSz+8xsW/S4pPnlHlvPwCjthQytucy069aHUHQgU0RCFqcHXgb+zN3PBS4F/sTMzgNuBja6+1nAxuj1gtkzOMqKjul73zAhwNUDF5GATRvg7r7b3X8RPR8CtgKrgOuA26PVbgeub1aRcewZLMUaPgHIZVKajSkiwZvRGLiZrQUuBB4Flrv7bqiFPLDsGJ+5ycw2mdmmvr6+uVV7HD0DoyyP2QOH2sFOTeYRkZDFDnAzKwLfBj7u7oNxP+fut7r7endf393dPZsap1WpOn3DpdhDKABdxTx90amHIiIhihXgZpalFt7fdPfvRIt7zGxl9P5KoLc5JU5v73CJStVZHnMIBWoBrh64iIQszlkoBnwN2Oru/zjhrbuBDdHzDcBdjS8vnj0D0SmEM+mBt+c0Bi4iQZv+nDt4I/B+4CkzeyJa9hfA54E7zOxGYDtwQ3NKnN6hc8BnEODdxQL9B2vT6XOZxJwOLyInkWkD3N0fBo51i5srG1vO7PREAb580fTT6Ou62mszNvcdKLFyUUtT6hIRaaZEdD33DIySSRldbTMI8Oi64ZpOLyKhSkaAD46yrD1P6jj3wpzsUIBrHFxEApWIAO8ZHJ3RGSgAy6KrFmo2poiEKhEBvmcg/jT6uvplZ+tnsIiIhCYRAd4zWJrRLEyAQjbN8o48O1452KSqRESaK/gAHy6VGS6VZxzgAKd2trJdAS4igQo+wA9N4pnBKYR1a5a0qgcuIsEKPsB76+eAz6IHvqazld2Do5TKlUaXJSLSdMEH+GxmYdad2tmKO7y8f6TRZYmINF1yAnyGpxECnLq0FUDj4CISpOADfCa3Upvs1M5agO9QD1xEAhR8gM/kVmqTdRfz5DMpHcgUkSAlIMDj30ptslTKWNPZyvZ9CnARCU/wAT7TW6lNpnPBRSRUQQf4bG6lNtmaJS3seOUg7t7AykREmi/oAJ/NrdQmW9PZylCpTP/B8QZWJiLSfEEH+GxupTZZ/UwUDaOISGjCDvA5TOKpq58LvmO/AlxEwhJ0gO/ur52/PZNbqU22Zol64CISpqADfMuuQTrbcnQXZx/gbfkMXcWczgUXkeAEHeCbd/azbvUizOLfSm0qa3QqoYgEKNgAHy6V2dY7zLo1i+e8LZ0LLiIhCjbAn9o5gDsNCfA1S1rZ1T9KuVJtQGUiIvMj2ADfvLMfgHWrG9MDr1Sd3bo/pogEJNwA39HPqZ2tdLbl5rytNToXXEQCFHSAN2L4BHRdcBEJU5AB3js4yq6BUdatXtSQ7a3oKNCSTbNl10BDticiMh+CDPDNO2tBe+GpjemBp1PGFWd3c++WHqpVXdRKRMIQZIA/sWM/6ZRx/imN6YEDXHPBSvqGSjy2fX/Dtiki0kxBBvjmHQOcs6KdQjbdsG2+9Zxl5DIpfvDU7oZtU0SkmYIL8GrVazMwG3QAs66Yz/DmV3dzz1N7NIwiIkEILsBf2neAodEyr2vA+d+Tvf2ClewZHOXxHf0N37aISKMFF+Cbo3BtdA8c4K3nLiOXTnGPhlFEJACZhS5gJsbKVb728Et0FfO8almx4dvvKGS5/Kwu7nl6D3/59nPnfJEsd2f/wXF27j/Izv0j7OofYWBknIGRcQZHximVq4yVq5TKVcrVKpWqU6465YozXqm9BjCDlBn5bJpiPk0xn6GzLc/yjjzLOwqsWFRg9eIWVi1poTUX1K9UROYgqP/tX7l/G1t2DXLL+y4mnZpbuB7LNResZOOzvTy5c2DGvfzhUpmfvbSPTb/az9O7Bnlm1wB7h8eOWMeAQjZNSy5NJmVk0kbajHQqRSpVC+q0GamUkcscbqM7HCyV2X9gjNHxCgfGKhwolY+qYXFrlpWLWli5qEB3Mc+SthydbVkWt+QoFjIU8xmKhQwdhSwdLRkWtWTJZxp3MFhE5k8wAb55Rz9ffeAFfvuiVVz9mhVN+56rzl1ONm387b3P8uXfu+i4U/XdnV/2DPPjrT088Fwvj2/vp1x1UgbLOwqc1tnGJacvpbMtx+LWWojmsylSc+zZ11WqztBorUfff3Cc/QfHGBgZp72QYVf/KE+/PMD+g2OMV45/ULa9kKG7mKerPc/KRYVDO4AViwqcsqiFFYsKLG3LkWrSTlNEZmdOAW5mVwNfAtLAbe7++YZUNcnoeIU/veMJlrXn+cw7zm/GVxyyqDXLZ995Pn999zP85hcf5B9uWMebXt196P29wyUeffEVfvriXr7/5G72RzdDXrW4hTe+qoszu4uctrSVbLr5hxfSKWNxa47FrTlOWzr1Ou5OqVxlZKxCqVylVK4wOl5hdLzKyHiFkfEKw6NlhktlegZH2dYzxOBImYofGfopg+72PMvaC3S25ehsy7GkNUdHS603317I0F7I0JaP/uUytER/abTk0uQzqXn5mYicTGYd4GaWBr4KXAXsBH5uZne7+zONKq7u7+59jhf6DvCNGy9hUUu20Zs/ynsvOY0L1yzhY996nA98/Wec2d1GqVxldLxyaEikLZdmTWcrV7x6GWevbKej0Py6ZsPMKGTTMzpnvurOgVKZwZFyNGY/xtBomaFSmaHRcV7oG+bJnWUORjuFuNIpI5dOkU0buUyKTCpFJm1k0ynSKSOTqj2vv5/P1IK/kE3Tkk1TyKbIZ2vL8pkUmXSqNgyVqg05Wa3BR7af2rBUyiATbTubTpFLp6LvqD1mo9f1OtIpiz5nmBFtG4zatszs0LYxDq1TX27RugCO4177uTq14TC8tvxwnYalDtdb/7zZ4Sb5Mf6Qqr9fXz81sYYG/bUnJ6a59MB/DXje3V8EMLNvAdcBDQ/wq1+zgs62HJed1dXoTR/Tead08N2PXMZX7n+eB57rpaOQJZtJcfFpOc7oauOUxS1NG4dfaCkz2gtZ2gtZVi1pOe66lapTKlcm9PCrjJUrjFWcsXKVsUqVcqXKeMUpRwdmy+5UKk7FnWp14mPtQPXImFOuVo84oDte30a1SrkyMfqkGQ7vFCYui3ZI0Z7keL8Dm7B+fWcyUX1ndLxtpOo7QTtyGzahqonbncn/xonfO3nHWN/hTlffkT+bw3Udq6Zb3n8xl5/VTSPNJcBXATsmvN4JXDJ5JTO7CbgpejlsZs/N9gs/PNsPQhewd+KC985+WyE6qv0nGbX/5G4/nAA/gzf9zZw+ftpUC+cS4FPt8I7aYbn7rcCtc/ieOTOzTe6+fiFrWEhqv9p/MrcfkvszmMtRpZ3AmgmvVwO75laOiIjENZcA/zlwlpmdbmY54D3A3Y0pS0REpjPrIRR3L5vZh4F7qZ1G+HV339KwyhprQYdwTgBq/8ntZG8/JPRnYH6sc5NEROSEppkVIiKBUoCLiAQqUQFuZleb2XNm9ryZ3TzF+2Zm/xS9/6SZXbQQdTZLjPafY2Y/NbOSmX1yIWpsphjtf2/0e3/SzH5iZusWos5midH+66K2P2Fmm8zssoWos1mma/+E9V5vZhUze/d81tcU7p6If9QOpL4AnAHkgM3AeZPWuRa4h9o57JcCjy503fPc/mXA64HPAZ9c6JoXoP1vAJZEz685CX//RQ4f93ot8OxC1z2f7Z+w3v3AD4B3L3Tdc/2XpB74oan97j4G1Kf2T3Qd8G9e8wiw2MxWznehTTJt+929191/DowvRIFNFqf9P3H3+l2rH6E2dyEp4rR/2KMUA9o4/kzx0MT5/w/wEeDbQO98FtcsSQrwqab2r5rFOqFKctvimGn7b6T211hSxGq/mb3LzJ4Fvg/8wTzVNh+mbb+ZrQLeBdwyj3U1VZICPM7U/ljT/wOV5LbFEbv9ZvYWagH+6aZWNL/iXtriv939HOB6YG5X5zixxGn/F4FPu3tlHuqZF8Hc0CGGOFP7kzz9P8ltiyNW+83stcBtwDXuvm+eapsPM/r9u/uDZnammXW5exIudBWn/euBb0VXSewCrjWzsrv/z/yU2HhJ6oHHmdp/N/CB6GyUS4EBd0/KHYxP9ksbTNt+MzsV+A7wfnf/5QLU2Exx2v8qi9IrOgMrByRlJzZt+939dHdf6+5rgTuBPw45vCFBPXA/xtR+M/tQ9P4t1I48Xws8DxwEPrhQ9TZanPab2QpgE9ABVM3s49SO1A8uWOENEvP3/1fAUuCfoxwre0KuUBez/b9DrQMzDowAvzvhoGbQYrY/cTSVXkQkUEkaQhEROakowEVEAqUAFxEJlAJcRCRQCnARkUApwOWkZWbDM1z/CjN7Q7PqEZkpBbhIfFdQu6KhyAlBAS6JZWafMrOPRs+/YGb3R8+vNLNvRM8/Z2abzewRM1seLXuHmT1qZo+b2Y/NbLmZrQU+BHwiup725QvTKpHDFOCSZA8C9aBdDxTNLAtcBjxE7ZKqj7j7umjdP4zWfRi41N0vpHZZ0k+5+6+oXcXuC+7+Ond/aP6aITK1xEylF5nCY8DFZtYOlIBfUAvyy4GPAmPA9yase1X0fDXwn9G14nPAS/NZtEhc6oFLYrn7OPArate8+Qm1XvdbgDOBrcD4hGuBVDjcofky8BV3vwD4I6Awj2WLxKYAl6R7EPhk9PgQtXHsJ6a5iNMi4OXo+YYJy4eA9mYUKTIbCnBJuoeAlcBP3b0HGI2WHc9ngf8ys4eAidfK/i7wLh3ElBOFrkYoIhIo9cBFRAKlABcRCZQCXEQkUApwEZFAKcBFRAKlABcRCZQCXEQkUP8Pd20hEG5R5QwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df_tdif['what']\n",
    "sns.distplot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí dejamos otras funciones para acceder desde objetos spacy a las frecuencias que hacen al tf-idf. No las aplicamos por una cuestión de tiempo y recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos estas dos funciones: docs_counter genera la frecuencia totald e palabras de todo el corpora, mientras que\n",
    "#word_counter genera la frecuencia de palabras de un documento.\n",
    "    \n",
    "    \n",
    "def docs_counter(docs):\n",
    "    word_count = Counter()\n",
    "    for doc in docs:\n",
    "        for token in doc:\n",
    "            word_count[str(token)] += 1\n",
    "    return word_count\n",
    "\n",
    "def word_counter(doc):\n",
    "    word_count = Counter()\n",
    "    for token in doc:\n",
    "        word_count[str(token)] += 1\n",
    "    return word_count\n",
    "\n",
    "def t_f(doc):\n",
    "    word_doc = dict(doc)\n",
    "    count = sum(doc.values())\n",
    "    word_tf  = {}\n",
    "    for key in word_doc:\n",
    "        word_tf.update( {key : word_doc[key]/count} )\n",
    "    return word_tf   \n",
    "\n",
    "def computeIDF(documents):\n",
    "    N = len(documents)\n",
    "    idfDict = {}\n",
    "    for document in documents:\n",
    "        for key  in document:\n",
    "            for document in documents:\n",
    "                if key in document:\n",
    "                    idfDict[key] += 1\n",
    "    \n",
    "    for key, val in idfDict.items():\n",
    "        idfDict[key] = math.log(N / float(val))\n",
    "    return idfDict \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### n-gramas.\n",
    " Se obtiene la frecuencia general de los n-gramas en cada uno de los corpora a a partir de los dc spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con esta función se obtienen los n-gramas de cada documento, se utiliza la librería textacy que pertenece a spacy.\n",
    "def ngrams(doc, n):\n",
    "    df = []\n",
    "    for word in doc:\n",
    "        df.append(list(textacy.extract.ngrams(word, n, min_freq=0,  filter_stops = False)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_nm_ngram = ngrams(df1_nm['text'], 2)\n",
    "df2_nm_ngram = ngrams(df2_nm['text'], 2)\n",
    "df3_nm_ngram = ngrams(df3_nm['text'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ngram_1 = docs_counter(df1_nm_ngram).most_common()\n",
    "freq_ngram_2 = docs_counter(df2_nm_ngram).most_common()\n",
    "freq_ngram_3 = docs_counter(df3_nm_ngram).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene la frecuencia de los n-gramas pero por documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ngram_doc_1 = [word_counter(doc) for doc in df1_nm_ngram]\n",
    "freq_ngram_doc_2 = [word_counter(doc) for doc in df2_nm_ngram]\n",
    "freq_ngram_doc_3 = [word_counter(doc) for doc in df3_nm_ngram]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Los enegramas nos muestran relaciones entre palabras que quedan invisibilizadas a primera visa si solo consideramos tokens individuales o palabras aisaldas. Son muy valisoos pues su información computacional se despliega con los modelos de entrenamiento a un nivel que a primera vista no podemos mesurar.Sin embargo, tomamos la decisión aquí de trabajar solo con enegramas de hasta dos palabras, pues el trabajo comutacional de seguir trabajando con ngramas de amyor grado supera las capacidades de nuestras computadoras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reemplazan las palabras con mucha variabilidad por un placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placeholder(docs):\n",
    "    placeholder = []\n",
    "    for doc in docs:\n",
    "        for token in doc:\n",
    "            tags = token.pos_\n",
    "            if tags == \"NUM\":\n",
    "                doc = str(doc).replace(str(token), \"DIGIT\")\n",
    "        placeholder.append(doc)\n",
    "    return placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_holder_1 = placeholder(df1_nm['text'])\n",
    "pl_holder_2 = placeholder(df2_nm['text'])\n",
    "pl_holder_3 = placeholder(df3_nm['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "La potencia de los placeholders reside en su capacidad para cortar la dimensionalidad de los vectores de palabras. Muchas veces tenemos conjuntos de palabras cuya naturaleza no aporta mucha información al problema. Desde un punto de vista estadístico linguístico, podríamos considerar la implementación de los placeholders como soluciones empíricas a los problemas que presentan, por ejemplo, la frecuncia de palabras muy bajas o las stopwords. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se reconocen las entidades y sus frecuencias en el corpora.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "for doc in df1_nm['text']:\n",
    "    for token in doc:\n",
    "        tags.append(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 56614),\n",
       " ('VERB', 36338),\n",
       " ('DET', 31199),\n",
       " ('ADP', 24755),\n",
       " ('ADJ', 24437),\n",
       " ('AUX', 23220),\n",
       " ('ADV', 20522),\n",
       " ('PUNCT', 18537),\n",
       " ('PART', 12203),\n",
       " ('PROPN', 9651),\n",
       " ('PRON', 9006),\n",
       " ('CCONJ', 8976),\n",
       " ('SCONJ', 8499),\n",
       " ('SPACE', 3420),\n",
       " ('NUM', 2788),\n",
       " ('INTJ', 2382),\n",
       " ('X', 1682),\n",
       " ('SYM', 193)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter(tags).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se identifica la similitud de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simil(docs):\n",
    "    for w1 in docs:\n",
    "        for w2 in docs:\n",
    "            print((w1.text, w2.text),' tienen una similaridad de: ', w1.similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('if', 'if')  tienen una similaridad de:  1.0\n",
      "('if', 'that')  tienen una similaridad de:  0.2003829\n",
      "('if', 'be')  tienen una similaridad de:  0.014723228\n",
      "('if', 'true')  tienen una similaridad de:  0.1247472\n",
      "('if', 'then')  tienen una similaridad de:  0.32815984\n",
      "('if', 'freedom')  tienen una similaridad de:  0.027155295\n",
      "('if', 'of')  tienen una similaridad de:  0.33316016\n",
      "('if', 'speech')  tienen una similaridad de:  0.06034837\n",
      "('if', 'be')  tienen una similaridad de:  0.07928275\n",
      "('if', 'doom')  tienen una similaridad de:  0.20957808\n",
      "('if', 'harassment')  tienen una similaridad de:  -0.051079396\n",
      "('if', 'be')  tienen una similaridad de:  0.051761236\n",
      "('if', 'subjective')  tienen una similaridad de:  0.13279614\n",
      "('if', 'now')  tienen una similaridad de:  0.22487116\n",
      "('if', 'i')  tienen una similaridad de:  0.1730055\n",
      "('if', 'can')  tienen una similaridad de:  -0.15280232\n",
      "('if', 'claim')  tienen una similaridad de:  -0.023919519\n",
      "('if', 'that')  tienen una similaridad de:  0.47389248\n",
      "('if', 'a')  tienen una similaridad de:  0.04943472\n",
      "('if', 'book')  tienen una similaridad de:  -0.03198968\n",
      "('if', 'i')  tienen una similaridad de:  0.038858864\n",
      "('if', 'do')  tienen una similaridad de:  -0.014009035\n",
      "('if', 'not')  tienen una similaridad de:  0.113111004\n",
      "('if', 'like')  tienen una similaridad de:  0.12771402\n",
      "('if', 'be')  tienen una similaridad de:  0.09429676\n",
      "('if', 'harass')  tienen una similaridad de:  0.0896189\n",
      "('if', '-PRON-')  tienen una similaridad de:  -0.07211381\n",
      "('if', 'and')  tienen una similaridad de:  0.16564919\n",
      "('if', '-PRON-')  tienen una similaridad de:  -0.1430247\n",
      "('if', 'will')  tienen una similaridad de:  -0.024915839\n",
      "('if', 'be')  tienen una similaridad de:  0.03364901\n",
      "('if', 'ban')  tienen una similaridad de:  0.029008508\n",
      "('that', 'if')  tienen una similaridad de:  0.2003829\n",
      "('that', 'that')  tienen una similaridad de:  1.0\n",
      "('that', 'be')  tienen una similaridad de:  -0.01245702\n",
      "('that', 'true')  tienen una similaridad de:  -0.00910809\n",
      "('that', 'then')  tienen una similaridad de:  0.04567193\n",
      "('that', 'freedom')  tienen una similaridad de:  0.04217142\n",
      "('that', 'of')  tienen una similaridad de:  0.077887215\n",
      "('that', 'speech')  tienen una similaridad de:  0.22053494\n",
      "('that', 'be')  tienen una similaridad de:  -0.115048684\n",
      "('that', 'doom')  tienen una similaridad de:  0.095588654\n",
      "('that', 'harassment')  tienen una similaridad de:  0.09697192\n",
      "('that', 'be')  tienen una similaridad de:  -0.071931824\n",
      "('that', 'subjective')  tienen una similaridad de:  0.04773206\n",
      "('that', 'now')  tienen una similaridad de:  0.075418055\n",
      "('that', 'i')  tienen una similaridad de:  0.24942012\n",
      "('that', 'can')  tienen una similaridad de:  -0.21781732\n",
      "('that', 'claim')  tienen una similaridad de:  -0.11172528\n",
      "('that', 'that')  tienen una similaridad de:  1.0\n",
      "('that', 'a')  tienen una similaridad de:  0.26629612\n",
      "('that', 'book')  tienen una similaridad de:  0.03890188\n",
      "('that', 'i')  tienen una similaridad de:  0.16926198\n",
      "('that', 'do')  tienen una similaridad de:  -0.07103283\n",
      "('that', 'not')  tienen una similaridad de:  0.07628366\n",
      "('that', 'like')  tienen una similaridad de:  -0.015037921\n",
      "('that', 'be')  tienen una similaridad de:  -0.13437758\n",
      "('that', 'harass')  tienen una similaridad de:  0.043887842\n",
      "('that', '-PRON-')  tienen una similaridad de:  -0.17550263\n",
      "('that', 'and')  tienen una similaridad de:  0.073183544\n",
      "('that', '-PRON-')  tienen una similaridad de:  -0.15073125\n",
      "('that', 'will')  tienen una similaridad de:  0.013508681\n",
      "('that', 'be')  tienen una similaridad de:  -0.11361566\n",
      "('that', 'ban')  tienen una similaridad de:  -0.086382255\n",
      "('be', 'if')  tienen una similaridad de:  0.014723228\n",
      "('be', 'that')  tienen una similaridad de:  -0.01245702\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'true')  tienen una similaridad de:  0.0042462363\n",
      "('be', 'then')  tienen una similaridad de:  -0.10999123\n",
      "('be', 'freedom')  tienen una similaridad de:  -0.089156896\n",
      "('be', 'of')  tienen una similaridad de:  0.028591486\n",
      "('be', 'speech')  tienen una similaridad de:  0.12735018\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'doom')  tienen una similaridad de:  0.091924675\n",
      "('be', 'harassment')  tienen una similaridad de:  -0.005780588\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'subjective')  tienen una similaridad de:  0.07882072\n",
      "('be', 'now')  tienen una similaridad de:  0.021121498\n",
      "('be', 'i')  tienen una similaridad de:  -0.17543036\n",
      "('be', 'can')  tienen una similaridad de:  0.23010083\n",
      "('be', 'claim')  tienen una similaridad de:  0.2951599\n",
      "('be', 'that')  tienen una similaridad de:  -0.0038979617\n",
      "('be', 'a')  tienen una similaridad de:  -0.13368551\n",
      "('be', 'book')  tienen una similaridad de:  0.13580891\n",
      "('be', 'i')  tienen una similaridad de:  -0.15369841\n",
      "('be', 'do')  tienen una similaridad de:  0.30577746\n",
      "('be', 'not')  tienen una similaridad de:  0.0057815607\n",
      "('be', 'like')  tienen una similaridad de:  0.21437785\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'harass')  tienen una similaridad de:  0.09118501\n",
      "('be', '-PRON-')  tienen una similaridad de:  -0.10795711\n",
      "('be', 'and')  tienen una similaridad de:  -0.07484178\n",
      "('be', '-PRON-')  tienen una similaridad de:  0.03856206\n",
      "('be', 'will')  tienen una similaridad de:  0.16057017\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'ban')  tienen una similaridad de:  0.0027359168\n",
      "('true', 'if')  tienen una similaridad de:  0.1247472\n",
      "('true', 'that')  tienen una similaridad de:  -0.00910809\n",
      "('true', 'be')  tienen una similaridad de:  0.0042462363\n",
      "('true', 'true')  tienen una similaridad de:  1.0\n",
      "('true', 'then')  tienen una similaridad de:  0.16779588\n",
      "('true', 'freedom')  tienen una similaridad de:  0.20055024\n",
      "('true', 'of')  tienen una similaridad de:  0.0993104\n",
      "('true', 'speech')  tienen una similaridad de:  0.07276608\n",
      "('true', 'be')  tienen una similaridad de:  -0.038905993\n",
      "('true', 'doom')  tienen una similaridad de:  0.18397567\n",
      "('true', 'harassment')  tienen una similaridad de:  0.24871741\n",
      "('true', 'be')  tienen una similaridad de:  -0.16502392\n",
      "('true', 'subjective')  tienen una similaridad de:  0.6902373\n",
      "('true', 'now')  tienen una similaridad de:  0.24575183\n",
      "('true', 'i')  tienen una similaridad de:  0.10935188\n",
      "('true', 'can')  tienen una similaridad de:  -0.05185384\n",
      "('true', 'claim')  tienen una similaridad de:  -0.05882643\n",
      "('true', 'that')  tienen una similaridad de:  -0.038517285\n",
      "('true', 'a')  tienen una similaridad de:  0.008191284\n",
      "('true', 'book')  tienen una similaridad de:  0.084399045\n",
      "('true', 'i')  tienen una similaridad de:  0.026848767\n",
      "('true', 'do')  tienen una similaridad de:  -0.09037773\n",
      "('true', 'not')  tienen una similaridad de:  0.12669988\n",
      "('true', 'like')  tienen una similaridad de:  -0.02534264\n",
      "('true', 'be')  tienen una similaridad de:  -0.185968\n",
      "('true', 'harass')  tienen una similaridad de:  0.372222\n",
      "('true', '-PRON-')  tienen una similaridad de:  0.2998248\n",
      "('true', 'and')  tienen una similaridad de:  0.08959572\n",
      "('true', '-PRON-')  tienen una similaridad de:  0.13159776\n",
      "('true', 'will')  tienen una similaridad de:  -0.16283208\n",
      "('true', 'be')  tienen una similaridad de:  -0.11924976\n",
      "('true', 'ban')  tienen una similaridad de:  0.17012255\n",
      "('then', 'if')  tienen una similaridad de:  0.32815984\n",
      "('then', 'that')  tienen una similaridad de:  0.04567193\n",
      "('then', 'be')  tienen una similaridad de:  -0.10999123\n",
      "('then', 'true')  tienen una similaridad de:  0.16779588\n",
      "('then', 'then')  tienen una similaridad de:  1.0\n",
      "('then', 'freedom')  tienen una similaridad de:  0.1499626\n",
      "('then', 'of')  tienen una similaridad de:  0.3480671\n",
      "('then', 'speech')  tienen una similaridad de:  -0.0861388\n",
      "('then', 'be')  tienen una similaridad de:  -0.07662123\n",
      "('then', 'doom')  tienen una similaridad de:  0.19652194\n",
      "('then', 'harassment')  tienen una similaridad de:  0.011533193\n",
      "('then', 'be')  tienen una similaridad de:  -0.1052829\n",
      "('then', 'subjective')  tienen una similaridad de:  0.1768329\n",
      "('then', 'now')  tienen una similaridad de:  0.6371181\n",
      "('then', 'i')  tienen una similaridad de:  0.11418854\n",
      "('then', 'can')  tienen una similaridad de:  0.0662073\n",
      "('then', 'claim')  tienen una similaridad de:  -0.07390437\n",
      "('then', 'that')  tienen una similaridad de:  0.22392336\n",
      "('then', 'a')  tienen una similaridad de:  -0.0009976854\n",
      "('then', 'book')  tienen una similaridad de:  -0.029132226\n",
      "('then', 'i')  tienen una similaridad de:  0.0027884168\n",
      "('then', 'do')  tienen una similaridad de:  -0.0703937\n",
      "('then', 'not')  tienen una similaridad de:  0.3563262\n",
      "('then', 'like')  tienen una similaridad de:  0.15804093\n",
      "('then', 'be')  tienen una similaridad de:  -0.09022575\n",
      "('then', 'harass')  tienen una similaridad de:  0.15703674\n",
      "('then', '-PRON-')  tienen una similaridad de:  -0.0103002805\n",
      "('then', 'and')  tienen una similaridad de:  0.044648837\n",
      "('then', '-PRON-')  tienen una similaridad de:  -0.10865013\n",
      "('then', 'will')  tienen una similaridad de:  0.036357436\n",
      "('then', 'be')  tienen una similaridad de:  -0.14181118\n",
      "('then', 'ban')  tienen una similaridad de:  0.11599501\n",
      "('freedom', 'if')  tienen una similaridad de:  0.027155295\n",
      "('freedom', 'that')  tienen una similaridad de:  0.04217142\n",
      "('freedom', 'be')  tienen una similaridad de:  -0.089156896\n",
      "('freedom', 'true')  tienen una similaridad de:  0.20055024\n",
      "('freedom', 'then')  tienen una similaridad de:  0.1499626\n",
      "('freedom', 'freedom')  tienen una similaridad de:  1.0\n",
      "('freedom', 'of')  tienen una similaridad de:  0.124031484\n",
      "('freedom', 'speech')  tienen una similaridad de:  0.35585016\n",
      "('freedom', 'be')  tienen una similaridad de:  -0.0012558828\n",
      "('freedom', 'doom')  tienen una similaridad de:  0.11777295\n",
      "('freedom', 'harassment')  tienen una similaridad de:  0.33097476\n",
      "('freedom', 'be')  tienen una similaridad de:  -0.037029095\n",
      "('freedom', 'subjective')  tienen una similaridad de:  0.009437047\n",
      "('freedom', 'now')  tienen una similaridad de:  0.004595887\n",
      "('freedom', 'i')  tienen una similaridad de:  0.038094968\n",
      "('freedom', 'can')  tienen una similaridad de:  0.12090802\n",
      "('freedom', 'claim')  tienen una similaridad de:  -0.06668565\n",
      "('freedom', 'that')  tienen una similaridad de:  0.06783257\n",
      "('freedom', 'a')  tienen una similaridad de:  0.13407457\n",
      "('freedom', 'book')  tienen una similaridad de:  0.26913348\n",
      "('freedom', 'i')  tienen una similaridad de:  -0.030940415\n",
      "('freedom', 'do')  tienen una similaridad de:  -0.070169464\n",
      "('freedom', 'not')  tienen una similaridad de:  0.19315526\n",
      "('freedom', 'like')  tienen una similaridad de:  -0.13261476\n",
      "('freedom', 'be')  tienen una similaridad de:  -0.104788095\n",
      "('freedom', 'harass')  tienen una similaridad de:  0.09289969\n",
      "('freedom', '-PRON-')  tienen una similaridad de:  0.19423473\n",
      "('freedom', 'and')  tienen una similaridad de:  0.15449566\n",
      "('freedom', '-PRON-')  tienen una similaridad de:  0.11533956\n",
      "('freedom', 'will')  tienen una similaridad de:  0.16823898\n",
      "('freedom', 'be')  tienen una similaridad de:  -0.05310833\n",
      "('freedom', 'ban')  tienen una similaridad de:  0.25645125\n",
      "('of', 'if')  tienen una similaridad de:  0.33316016\n",
      "('of', 'that')  tienen una similaridad de:  0.077887215\n",
      "('of', 'be')  tienen una similaridad de:  0.028591486\n",
      "('of', 'true')  tienen una similaridad de:  0.0993104\n",
      "('of', 'then')  tienen una similaridad de:  0.3480671\n",
      "('of', 'freedom')  tienen una similaridad de:  0.124031484\n",
      "('of', 'of')  tienen una similaridad de:  1.0\n",
      "('of', 'speech')  tienen una similaridad de:  0.07507881\n",
      "('of', 'be')  tienen una similaridad de:  0.07745382\n",
      "('of', 'doom')  tienen una similaridad de:  0.19535534\n",
      "('of', 'harassment')  tienen una similaridad de:  -0.0126787145\n",
      "('of', 'be')  tienen una similaridad de:  0.012927245\n",
      "('of', 'subjective')  tienen una similaridad de:  -0.065085895\n",
      "('of', 'now')  tienen una similaridad de:  0.30934444\n",
      "('of', 'i')  tienen una similaridad de:  0.04345669\n",
      "('of', 'can')  tienen una similaridad de:  -0.06286729\n",
      "('of', 'claim')  tienen una similaridad de:  0.045448404\n",
      "('of', 'that')  tienen una similaridad de:  0.39341542\n",
      "('of', 'a')  tienen una similaridad de:  -0.037390612\n",
      "('of', 'book')  tienen una similaridad de:  0.039434798\n",
      "('of', 'i')  tienen una similaridad de:  -0.17559657\n",
      "('of', 'do')  tienen una similaridad de:  -0.17687495\n",
      "('of', 'not')  tienen una similaridad de:  0.123001516\n",
      "('of', 'like')  tienen una similaridad de:  0.17814507\n",
      "('of', 'be')  tienen una similaridad de:  0.05216647\n",
      "('of', 'harass')  tienen una similaridad de:  -0.15080507\n",
      "('of', '-PRON-')  tienen una similaridad de:  0.02508841\n",
      "('of', 'and')  tienen una similaridad de:  0.2639736\n",
      "('of', '-PRON-')  tienen una similaridad de:  0.11098407\n",
      "('of', 'will')  tienen una similaridad de:  0.0559058\n",
      "('of', 'be')  tienen una similaridad de:  0.08824294\n",
      "('of', 'ban')  tienen una similaridad de:  0.111512855\n",
      "('speech', 'if')  tienen una similaridad de:  0.06034837\n",
      "('speech', 'that')  tienen una similaridad de:  0.22053494\n",
      "('speech', 'be')  tienen una similaridad de:  0.12735018\n",
      "('speech', 'true')  tienen una similaridad de:  0.07276608\n",
      "('speech', 'then')  tienen una similaridad de:  -0.0861388\n",
      "('speech', 'freedom')  tienen una similaridad de:  0.35585016\n",
      "('speech', 'of')  tienen una similaridad de:  0.07507881\n",
      "('speech', 'speech')  tienen una similaridad de:  1.0\n",
      "('speech', 'be')  tienen una similaridad de:  0.14254604\n",
      "('speech', 'doom')  tienen una similaridad de:  0.12175662\n",
      "('speech', 'harassment')  tienen una similaridad de:  0.39728877\n",
      "('speech', 'be')  tienen una similaridad de:  0.058131557\n",
      "('speech', 'subjective')  tienen una similaridad de:  0.0054155644\n",
      "('speech', 'now')  tienen una similaridad de:  -0.17668808\n",
      "('speech', 'i')  tienen una similaridad de:  0.14579901\n",
      "('speech', 'can')  tienen una similaridad de:  -0.033419594\n",
      "('speech', 'claim')  tienen una similaridad de:  -0.021853816\n",
      "('speech', 'that')  tienen una similaridad de:  0.03222512\n",
      "('speech', 'a')  tienen una similaridad de:  -0.048229437\n",
      "('speech', 'book')  tienen una similaridad de:  0.3970432\n",
      "('speech', 'i')  tienen una similaridad de:  0.19304965\n",
      "('speech', 'do')  tienen una similaridad de:  -0.14396872\n",
      "('speech', 'not')  tienen una similaridad de:  -0.16771367\n",
      "('speech', 'like')  tienen una similaridad de:  -0.04499965\n",
      "('speech', 'be')  tienen una similaridad de:  -0.021731675\n",
      "('speech', 'harass')  tienen una similaridad de:  0.15042073\n",
      "('speech', '-PRON-')  tienen una similaridad de:  0.020731803\n",
      "('speech', 'and')  tienen una similaridad de:  0.09804313\n",
      "('speech', '-PRON-')  tienen una similaridad de:  0.14770074\n",
      "('speech', 'will')  tienen una similaridad de:  0.2419773\n",
      "('speech', 'be')  tienen una similaridad de:  0.0060365633\n",
      "('speech', 'ban')  tienen una similaridad de:  0.093238786\n",
      "('be', 'if')  tienen una similaridad de:  0.07928275\n",
      "('be', 'that')  tienen una similaridad de:  -0.115048684\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'true')  tienen una similaridad de:  -0.038905993\n",
      "('be', 'then')  tienen una similaridad de:  -0.07662123\n",
      "('be', 'freedom')  tienen una similaridad de:  -0.0012558828\n",
      "('be', 'of')  tienen una similaridad de:  0.07745382\n",
      "('be', 'speech')  tienen una similaridad de:  0.14254604\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'doom')  tienen una similaridad de:  0.119993\n",
      "('be', 'harassment')  tienen una similaridad de:  0.13270448\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'subjective')  tienen una similaridad de:  0.0671311\n",
      "('be', 'now')  tienen una similaridad de:  -0.1103441\n",
      "('be', 'i')  tienen una similaridad de:  0.018967729\n",
      "('be', 'can')  tienen una similaridad de:  0.18525818\n",
      "('be', 'claim')  tienen una similaridad de:  0.36905095\n",
      "('be', 'that')  tienen una similaridad de:  -0.113649465\n",
      "('be', 'a')  tienen una similaridad de:  -0.13808376\n",
      "('be', 'book')  tienen una similaridad de:  0.095144905\n",
      "('be', 'i')  tienen una similaridad de:  -0.03632886\n",
      "('be', 'do')  tienen una similaridad de:  0.34109887\n",
      "('be', 'not')  tienen una similaridad de:  -0.048101697\n",
      "('be', 'like')  tienen una similaridad de:  0.2550264\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'harass')  tienen una similaridad de:  0.024570214\n",
      "('be', '-PRON-')  tienen una similaridad de:  -0.07031376\n",
      "('be', 'and')  tienen una similaridad de:  -0.19067602\n",
      "('be', '-PRON-')  tienen una similaridad de:  0.12685783\n",
      "('be', 'will')  tienen una similaridad de:  0.21848492\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'ban')  tienen una similaridad de:  0.20472221\n",
      "('doom', 'if')  tienen una similaridad de:  0.20957808\n",
      "('doom', 'that')  tienen una similaridad de:  0.095588654\n",
      "('doom', 'be')  tienen una similaridad de:  0.091924675\n",
      "('doom', 'true')  tienen una similaridad de:  0.18397567\n",
      "('doom', 'then')  tienen una similaridad de:  0.19652194\n",
      "('doom', 'freedom')  tienen una similaridad de:  0.11777295\n",
      "('doom', 'of')  tienen una similaridad de:  0.19535534\n",
      "('doom', 'speech')  tienen una similaridad de:  0.12175662\n",
      "('doom', 'be')  tienen una similaridad de:  0.119993\n",
      "('doom', 'doom')  tienen una similaridad de:  1.0\n",
      "('doom', 'harassment')  tienen una similaridad de:  0.45060167\n",
      "('doom', 'be')  tienen una similaridad de:  0.009541399\n",
      "('doom', 'subjective')  tienen una similaridad de:  0.1986285\n",
      "('doom', 'now')  tienen una similaridad de:  0.23161173\n",
      "('doom', 'i')  tienen una similaridad de:  0.08897731\n",
      "('doom', 'can')  tienen una similaridad de:  -0.06487525\n",
      "('doom', 'claim')  tienen una similaridad de:  0.08699026\n",
      "('doom', 'that')  tienen una similaridad de:  0.15764411\n",
      "('doom', 'a')  tienen una similaridad de:  0.18966843\n",
      "('doom', 'book')  tienen una similaridad de:  0.16504939\n",
      "('doom', 'i')  tienen una similaridad de:  0.073498875\n",
      "('doom', 'do')  tienen una similaridad de:  0.08618101\n",
      "('doom', 'not')  tienen una similaridad de:  0.04837996\n",
      "('doom', 'like')  tienen una similaridad de:  -0.01561831\n",
      "('doom', 'be')  tienen una similaridad de:  0.19680713\n",
      "('doom', 'harass')  tienen una similaridad de:  0.47482824\n",
      "('doom', '-PRON-')  tienen una similaridad de:  0.12207218\n",
      "('doom', 'and')  tienen una similaridad de:  0.17953219\n",
      "('doom', '-PRON-')  tienen una similaridad de:  0.08218168\n",
      "('doom', 'will')  tienen una similaridad de:  0.04037502\n",
      "('doom', 'be')  tienen una similaridad de:  0.056893345\n",
      "('doom', 'ban')  tienen una similaridad de:  0.4599081\n",
      "('harassment', 'if')  tienen una similaridad de:  -0.051079396\n",
      "('harassment', 'that')  tienen una similaridad de:  0.09697192\n",
      "('harassment', 'be')  tienen una similaridad de:  -0.005780588\n",
      "('harassment', 'true')  tienen una similaridad de:  0.24871741\n",
      "('harassment', 'then')  tienen una similaridad de:  0.011533193\n",
      "('harassment', 'freedom')  tienen una similaridad de:  0.33097476\n",
      "('harassment', 'of')  tienen una similaridad de:  -0.0126787145\n",
      "('harassment', 'speech')  tienen una similaridad de:  0.39728877\n",
      "('harassment', 'be')  tienen una similaridad de:  0.13270448\n",
      "('harassment', 'doom')  tienen una similaridad de:  0.45060167\n",
      "('harassment', 'harassment')  tienen una similaridad de:  1.0\n",
      "('harassment', 'be')  tienen una similaridad de:  0.01855298\n",
      "('harassment', 'subjective')  tienen una similaridad de:  0.063318476\n",
      "('harassment', 'now')  tienen una similaridad de:  0.0027361684\n",
      "('harassment', 'i')  tienen una similaridad de:  0.18713257\n",
      "('harassment', 'can')  tienen una similaridad de:  0.028266734\n",
      "('harassment', 'claim')  tienen una similaridad de:  -0.025495537\n",
      "('harassment', 'that')  tienen una similaridad de:  -0.097387396\n",
      "('harassment', 'a')  tienen una similaridad de:  0.16729894\n",
      "('harassment', 'book')  tienen una similaridad de:  0.35082218\n",
      "('harassment', 'i')  tienen una similaridad de:  0.21408865\n",
      "('harassment', 'do')  tienen una similaridad de:  0.13169387\n",
      "('harassment', 'not')  tienen una similaridad de:  0.059987493\n",
      "('harassment', 'like')  tienen una similaridad de:  0.13507783\n",
      "('harassment', 'be')  tienen una similaridad de:  -0.020937202\n",
      "('harassment', 'harass')  tienen una similaridad de:  0.33837056\n",
      "('harassment', '-PRON-')  tienen una similaridad de:  0.14433128\n",
      "('harassment', 'and')  tienen una similaridad de:  0.032956637\n",
      "('harassment', '-PRON-')  tienen una similaridad de:  0.16172187\n",
      "('harassment', 'will')  tienen una similaridad de:  0.19031131\n",
      "('harassment', 'be')  tienen una similaridad de:  -0.04838609\n",
      "('harassment', 'ban')  tienen una similaridad de:  0.3938702\n",
      "('be', 'if')  tienen una similaridad de:  0.051761236\n",
      "('be', 'that')  tienen una similaridad de:  -0.071931824\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'true')  tienen una similaridad de:  -0.16502392\n",
      "('be', 'then')  tienen una similaridad de:  -0.1052829\n",
      "('be', 'freedom')  tienen una similaridad de:  -0.037029095\n",
      "('be', 'of')  tienen una similaridad de:  0.012927245\n",
      "('be', 'speech')  tienen una similaridad de:  0.058131557\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'doom')  tienen una similaridad de:  0.009541399\n",
      "('be', 'harassment')  tienen una similaridad de:  0.01855298\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'subjective')  tienen una similaridad de:  -0.05183048\n",
      "('be', 'now')  tienen una similaridad de:  -0.054194458\n",
      "('be', 'i')  tienen una similaridad de:  -0.109602414\n",
      "('be', 'can')  tienen una similaridad de:  0.23656943\n",
      "('be', 'claim')  tienen una similaridad de:  0.45740175\n",
      "('be', 'that')  tienen una similaridad de:  -0.03179813\n",
      "('be', 'a')  tienen una similaridad de:  -0.13651346\n",
      "('be', 'book')  tienen una similaridad de:  0.057513557\n",
      "('be', 'i')  tienen una similaridad de:  -0.08505659\n",
      "('be', 'do')  tienen una similaridad de:  0.37104824\n",
      "('be', 'not')  tienen una similaridad de:  0.09304366\n",
      "('be', 'like')  tienen una similaridad de:  0.32754084\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'harass')  tienen una similaridad de:  -0.07855498\n",
      "('be', '-PRON-')  tienen una similaridad de:  -0.12786719\n",
      "('be', 'and')  tienen una similaridad de:  -0.076059446\n",
      "('be', '-PRON-')  tienen una similaridad de:  0.013898109\n",
      "('be', 'will')  tienen una similaridad de:  0.23828572\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'ban')  tienen una similaridad de:  0.12887473\n",
      "('subjective', 'if')  tienen una similaridad de:  0.13279614\n",
      "('subjective', 'that')  tienen una similaridad de:  0.04773206\n",
      "('subjective', 'be')  tienen una similaridad de:  0.07882072\n",
      "('subjective', 'true')  tienen una similaridad de:  0.6902373\n",
      "('subjective', 'then')  tienen una similaridad de:  0.1768329\n",
      "('subjective', 'freedom')  tienen una similaridad de:  0.009437047\n",
      "('subjective', 'of')  tienen una similaridad de:  -0.065085895\n",
      "('subjective', 'speech')  tienen una similaridad de:  0.0054155644\n",
      "('subjective', 'be')  tienen una similaridad de:  0.0671311\n",
      "('subjective', 'doom')  tienen una similaridad de:  0.1986285\n",
      "('subjective', 'harassment')  tienen una similaridad de:  0.063318476\n",
      "('subjective', 'be')  tienen una similaridad de:  -0.05183048\n",
      "('subjective', 'subjective')  tienen una similaridad de:  1.0\n",
      "('subjective', 'now')  tienen una similaridad de:  0.2028915\n",
      "('subjective', 'i')  tienen una similaridad de:  -0.010130783\n",
      "('subjective', 'can')  tienen una similaridad de:  0.024731038\n",
      "('subjective', 'claim')  tienen una similaridad de:  0.03576931\n",
      "('subjective', 'that')  tienen una similaridad de:  -0.017983604\n",
      "('subjective', 'a')  tienen una similaridad de:  0.098065525\n",
      "('subjective', 'book')  tienen una similaridad de:  -0.005381944\n",
      "('subjective', 'i')  tienen una similaridad de:  0.012661456\n",
      "('subjective', 'do')  tienen una similaridad de:  0.034752134\n",
      "('subjective', 'not')  tienen una similaridad de:  0.26799315\n",
      "('subjective', 'like')  tienen una similaridad de:  0.03495921\n",
      "('subjective', 'be')  tienen una similaridad de:  -0.00050386175\n",
      "('subjective', 'harass')  tienen una similaridad de:  0.3240076\n",
      "('subjective', '-PRON-')  tienen una similaridad de:  0.10850234\n",
      "('subjective', 'and')  tienen una similaridad de:  0.10653235\n",
      "('subjective', '-PRON-')  tienen una similaridad de:  -0.022013795\n",
      "('subjective', 'will')  tienen una similaridad de:  -0.04231798\n",
      "('subjective', 'be')  tienen una similaridad de:  0.011695626\n",
      "('subjective', 'ban')  tienen una similaridad de:  0.16307719\n",
      "('now', 'if')  tienen una similaridad de:  0.22487116\n",
      "('now', 'that')  tienen una similaridad de:  0.075418055\n",
      "('now', 'be')  tienen una similaridad de:  0.021121498\n",
      "('now', 'true')  tienen una similaridad de:  0.24575183\n",
      "('now', 'then')  tienen una similaridad de:  0.6371181\n",
      "('now', 'freedom')  tienen una similaridad de:  0.004595887\n",
      "('now', 'of')  tienen una similaridad de:  0.30934444\n",
      "('now', 'speech')  tienen una similaridad de:  -0.17668808\n",
      "('now', 'be')  tienen una similaridad de:  -0.1103441\n",
      "('now', 'doom')  tienen una similaridad de:  0.23161173\n",
      "('now', 'harassment')  tienen una similaridad de:  0.0027361684\n",
      "('now', 'be')  tienen una similaridad de:  -0.054194458\n",
      "('now', 'subjective')  tienen una similaridad de:  0.2028915\n",
      "('now', 'now')  tienen una similaridad de:  1.0\n",
      "('now', 'i')  tienen una similaridad de:  0.12418774\n",
      "('now', 'can')  tienen una similaridad de:  -0.081553236\n",
      "('now', 'claim')  tienen una similaridad de:  -0.11821977\n",
      "('now', 'that')  tienen una similaridad de:  0.19469565\n",
      "('now', 'a')  tienen una similaridad de:  -0.05291251\n",
      "('now', 'book')  tienen una similaridad de:  0.08409208\n",
      "('now', 'i')  tienen una similaridad de:  -0.01142908\n",
      "('now', 'do')  tienen una similaridad de:  -0.19482802\n",
      "('now', 'not')  tienen una similaridad de:  0.31099492\n",
      "('now', 'like')  tienen una similaridad de:  0.16088355\n",
      "('now', 'be')  tienen una similaridad de:  -0.027228924\n",
      "('now', 'harass')  tienen una similaridad de:  -0.0043993904\n",
      "('now', '-PRON-')  tienen una similaridad de:  0.026854811\n",
      "('now', 'and')  tienen una similaridad de:  0.024909774\n",
      "('now', '-PRON-')  tienen una similaridad de:  -0.045272898\n",
      "('now', 'will')  tienen una similaridad de:  -0.15202692\n",
      "('now', 'be')  tienen una similaridad de:  -0.16434018\n",
      "('now', 'ban')  tienen una similaridad de:  -0.008658049\n",
      "('i', 'if')  tienen una similaridad de:  0.1730055\n",
      "('i', 'that')  tienen una similaridad de:  0.24942012\n",
      "('i', 'be')  tienen una similaridad de:  -0.17543036\n",
      "('i', 'true')  tienen una similaridad de: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-92e5f5bd3d97>:4: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print((w1.text, w2.text),' tienen una similaridad de: ', w1.similarity(w2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.10935188\n",
      "('i', 'then')  tienen una similaridad de:  0.11418854\n",
      "('i', 'freedom')  tienen una similaridad de:  0.038094968\n",
      "('i', 'of')  tienen una similaridad de:  0.04345669\n",
      "('i', 'speech')  tienen una similaridad de:  0.14579901\n",
      "('i', 'be')  tienen una similaridad de:  0.018967729\n",
      "('i', 'doom')  tienen una similaridad de:  0.08897731\n",
      "('i', 'harassment')  tienen una similaridad de:  0.18713257\n",
      "('i', 'be')  tienen una similaridad de:  -0.109602414\n",
      "('i', 'subjective')  tienen una similaridad de:  -0.010130783\n",
      "('i', 'now')  tienen una similaridad de:  0.12418774\n",
      "('i', 'i')  tienen una similaridad de:  1.0\n",
      "('i', 'can')  tienen una similaridad de:  -0.18635876\n",
      "('i', 'claim')  tienen una similaridad de:  -0.12512696\n",
      "('i', 'that')  tienen una similaridad de:  0.016048897\n",
      "('i', 'a')  tienen una similaridad de:  0.023293877\n",
      "('i', 'book')  tienen una similaridad de:  0.13005404\n",
      "('i', 'i')  tienen una similaridad de:  1.0\n",
      "('i', 'do')  tienen una similaridad de:  -0.038980722\n",
      "('i', 'not')  tienen una similaridad de:  0.0050362446\n",
      "('i', 'like')  tienen una similaridad de:  0.018227693\n",
      "('i', 'be')  tienen una similaridad de:  -0.02606488\n",
      "('i', 'harass')  tienen una similaridad de:  0.16800489\n",
      "('i', '-PRON-')  tienen una similaridad de:  0.02809503\n",
      "('i', 'and')  tienen una similaridad de:  -0.04851899\n",
      "('i', '-PRON-')  tienen una similaridad de:  0.1303855\n",
      "('i', 'will')  tienen una similaridad de:  0.022782143\n",
      "('i', 'be')  tienen una similaridad de:  -0.116867065\n",
      "('i', 'ban')  tienen una similaridad de:  0.04437892\n",
      "('can', 'if')  tienen una similaridad de:  -0.15280232\n",
      "('can', 'that')  tienen una similaridad de:  -0.21781732\n",
      "('can', 'be')  tienen una similaridad de:  0.23010083\n",
      "('can', 'true')  tienen una similaridad de:  -0.05185384\n",
      "('can', 'then')  tienen una similaridad de:  0.0662073\n",
      "('can', 'freedom')  tienen una similaridad de:  0.12090802\n",
      "('can', 'of')  tienen una similaridad de:  -0.06286729\n",
      "('can', 'speech')  tienen una similaridad de:  -0.033419594\n",
      "('can', 'be')  tienen una similaridad de:  0.18525818\n",
      "('can', 'doom')  tienen una similaridad de:  -0.06487525\n",
      "('can', 'harassment')  tienen una similaridad de:  0.028266734\n",
      "('can', 'be')  tienen una similaridad de:  0.23656943\n",
      "('can', 'subjective')  tienen una similaridad de:  0.024731038\n",
      "('can', 'now')  tienen una similaridad de:  -0.081553236\n",
      "('can', 'i')  tienen una similaridad de:  -0.18635876\n",
      "('can', 'can')  tienen una similaridad de:  1.0\n",
      "('can', 'claim')  tienen una similaridad de:  -0.0005836754\n",
      "('can', 'that')  tienen una similaridad de:  -0.22195092\n",
      "('can', 'a')  tienen una similaridad de:  0.07295296\n",
      "('can', 'book')  tienen una similaridad de:  -0.02140256\n",
      "('can', 'i')  tienen una similaridad de:  -0.101407416\n",
      "('can', 'do')  tienen una similaridad de:  0.39770728\n",
      "('can', 'not')  tienen una similaridad de:  0.20074034\n",
      "('can', 'like')  tienen una similaridad de:  0.023268502\n",
      "('can', 'be')  tienen una similaridad de:  0.11779962\n",
      "('can', 'harass')  tienen una similaridad de:  -0.07136258\n",
      "('can', '-PRON-')  tienen una similaridad de:  -0.045706403\n",
      "('can', 'and')  tienen una similaridad de:  0.019247292\n",
      "('can', '-PRON-')  tienen una similaridad de:  0.06492424\n",
      "('can', 'will')  tienen una similaridad de:  0.62892777\n",
      "('can', 'be')  tienen una similaridad de:  0.14479291\n",
      "('can', 'ban')  tienen una similaridad de:  0.012643506\n",
      "('claim', 'if')  tienen una similaridad de:  -0.023919519\n",
      "('claim', 'that')  tienen una similaridad de:  -0.11172528\n",
      "('claim', 'be')  tienen una similaridad de:  0.2951599\n",
      "('claim', 'true')  tienen una similaridad de:  -0.05882643\n",
      "('claim', 'then')  tienen una similaridad de:  -0.07390437\n",
      "('claim', 'freedom')  tienen una similaridad de:  -0.06668565\n",
      "('claim', 'of')  tienen una similaridad de:  0.045448404\n",
      "('claim', 'speech')  tienen una similaridad de:  -0.021853816\n",
      "('claim', 'be')  tienen una similaridad de:  0.36905095\n",
      "('claim', 'doom')  tienen una similaridad de:  0.08699026\n",
      "('claim', 'harassment')  tienen una similaridad de:  -0.025495537\n",
      "('claim', 'be')  tienen una similaridad de:  0.45740175\n",
      "('claim', 'subjective')  tienen una similaridad de:  0.03576931\n",
      "('claim', 'now')  tienen una similaridad de:  -0.11821977\n",
      "('claim', 'i')  tienen una similaridad de:  -0.12512696\n",
      "('claim', 'can')  tienen una similaridad de:  -0.0005836754\n",
      "('claim', 'claim')  tienen una similaridad de:  1.0\n",
      "('claim', 'that')  tienen una similaridad de:  0.04337621\n",
      "('claim', 'a')  tienen una similaridad de:  -0.08428534\n",
      "('claim', 'book')  tienen una similaridad de:  0.10836855\n",
      "('claim', 'i')  tienen una similaridad de:  -0.04536694\n",
      "('claim', 'do')  tienen una similaridad de:  0.3011573\n",
      "('claim', 'not')  tienen una similaridad de:  0.060607333\n",
      "('claim', 'like')  tienen una similaridad de:  0.3795749\n",
      "('claim', 'be')  tienen una similaridad de:  0.43294317\n",
      "('claim', 'harass')  tienen una similaridad de:  0.0055162045\n",
      "('claim', '-PRON-')  tienen una similaridad de:  -0.050733943\n",
      "('claim', 'and')  tienen una similaridad de:  -0.055968575\n",
      "('claim', '-PRON-')  tienen una similaridad de:  0.075684525\n",
      "('claim', 'will')  tienen una similaridad de:  -0.017036472\n",
      "('claim', 'be')  tienen una similaridad de:  0.56608325\n",
      "('claim', 'ban')  tienen una similaridad de:  0.3890207\n",
      "('that', 'if')  tienen una similaridad de:  0.47389248\n",
      "('that', 'that')  tienen una similaridad de:  1.0\n",
      "('that', 'be')  tienen una similaridad de:  -0.0038979617\n",
      "('that', 'true')  tienen una similaridad de:  -0.038517285\n",
      "('that', 'then')  tienen una similaridad de:  0.22392336\n",
      "('that', 'freedom')  tienen una similaridad de:  0.06783257\n",
      "('that', 'of')  tienen una similaridad de:  0.39341542\n",
      "('that', 'speech')  tienen una similaridad de:  0.03222512\n",
      "('that', 'be')  tienen una similaridad de:  -0.113649465\n",
      "('that', 'doom')  tienen una similaridad de:  0.15764411\n",
      "('that', 'harassment')  tienen una similaridad de:  -0.097387396\n",
      "('that', 'be')  tienen una similaridad de:  -0.03179813\n",
      "('that', 'subjective')  tienen una similaridad de:  -0.017983604\n",
      "('that', 'now')  tienen una similaridad de:  0.19469565\n",
      "('that', 'i')  tienen una similaridad de:  0.016048897\n",
      "('that', 'can')  tienen una similaridad de:  -0.22195092\n",
      "('that', 'claim')  tienen una similaridad de:  0.04337621\n",
      "('that', 'that')  tienen una similaridad de:  1.0\n",
      "('that', 'a')  tienen una similaridad de:  0.09734382\n",
      "('that', 'book')  tienen una similaridad de:  0.09672875\n",
      "('that', 'i')  tienen una similaridad de:  -0.19984314\n",
      "('that', 'do')  tienen una similaridad de:  -0.18365099\n",
      "('that', 'not')  tienen una similaridad de:  0.0461737\n",
      "('that', 'like')  tienen una similaridad de:  0.07356866\n",
      "('that', 'be')  tienen una similaridad de:  0.06418628\n",
      "('that', 'harass')  tienen una similaridad de:  0.032204293\n",
      "('that', '-PRON-')  tienen una similaridad de:  -0.08055038\n",
      "('that', 'and')  tienen una similaridad de:  0.091797374\n",
      "('that', '-PRON-')  tienen una similaridad de:  -0.11603953\n",
      "('that', 'will')  tienen una similaridad de:  -0.06659386\n",
      "('that', 'be')  tienen una similaridad de:  0.10469144\n",
      "('that', 'ban')  tienen una similaridad de:  0.055136975\n",
      "('a', 'if')  tienen una similaridad de:  0.04943472\n",
      "('a', 'that')  tienen una similaridad de:  0.26629612\n",
      "('a', 'be')  tienen una similaridad de:  -0.13368551\n",
      "('a', 'true')  tienen una similaridad de:  0.008191284\n",
      "('a', 'then')  tienen una similaridad de:  -0.0009976854\n",
      "('a', 'freedom')  tienen una similaridad de:  0.13407457\n",
      "('a', 'of')  tienen una similaridad de:  -0.037390612\n",
      "('a', 'speech')  tienen una similaridad de:  -0.048229437\n",
      "('a', 'be')  tienen una similaridad de:  -0.13808376\n",
      "('a', 'doom')  tienen una similaridad de:  0.18966843\n",
      "('a', 'harassment')  tienen una similaridad de:  0.16729894\n",
      "('a', 'be')  tienen una similaridad de:  -0.13651346\n",
      "('a', 'subjective')  tienen una similaridad de:  0.098065525\n",
      "('a', 'now')  tienen una similaridad de:  -0.05291251\n",
      "('a', 'i')  tienen una similaridad de:  0.023293877\n",
      "('a', 'can')  tienen una similaridad de:  0.07295296\n",
      "('a', 'claim')  tienen una similaridad de:  -0.08428534\n",
      "('a', 'that')  tienen una similaridad de:  0.09734382\n",
      "('a', 'a')  tienen una similaridad de:  1.0\n",
      "('a', 'book')  tienen una similaridad de:  0.08311238\n",
      "('a', 'i')  tienen una similaridad de:  0.07141876\n",
      "('a', 'do')  tienen una similaridad de:  -0.0017918864\n",
      "('a', 'not')  tienen una similaridad de:  0.01307925\n",
      "('a', 'like')  tienen una similaridad de:  -0.060565405\n",
      "('a', 'be')  tienen una similaridad de:  -0.065256216\n",
      "('a', 'harass')  tienen una similaridad de:  0.1448032\n",
      "('a', '-PRON-')  tienen una similaridad de:  -0.24018882\n",
      "('a', 'and')  tienen una similaridad de:  -0.11193985\n",
      "('a', '-PRON-')  tienen una similaridad de:  -0.11754079\n",
      "('a', 'will')  tienen una similaridad de:  -0.0005832484\n",
      "('a', 'be')  tienen una similaridad de:  -0.14793186\n",
      "('a', 'ban')  tienen una similaridad de:  0.15632208\n",
      "('book', 'if')  tienen una similaridad de:  -0.03198968\n",
      "('book', 'that')  tienen una similaridad de:  0.03890188\n",
      "('book', 'be')  tienen una similaridad de:  0.13580891\n",
      "('book', 'true')  tienen una similaridad de:  0.084399045\n",
      "('book', 'then')  tienen una similaridad de:  -0.029132226\n",
      "('book', 'freedom')  tienen una similaridad de:  0.26913348\n",
      "('book', 'of')  tienen una similaridad de:  0.039434798\n",
      "('book', 'speech')  tienen una similaridad de:  0.3970432\n",
      "('book', 'be')  tienen una similaridad de:  0.095144905\n",
      "('book', 'doom')  tienen una similaridad de:  0.16504939\n",
      "('book', 'harassment')  tienen una similaridad de:  0.35082218\n",
      "('book', 'be')  tienen una similaridad de:  0.057513557\n",
      "('book', 'subjective')  tienen una similaridad de:  -0.005381944\n",
      "('book', 'now')  tienen una similaridad de:  0.08409208\n",
      "('book', 'i')  tienen una similaridad de:  0.13005404\n",
      "('book', 'can')  tienen una similaridad de:  -0.02140256\n",
      "('book', 'claim')  tienen una similaridad de:  0.10836855\n",
      "('book', 'that')  tienen una similaridad de:  0.09672875\n",
      "('book', 'a')  tienen una similaridad de:  0.08311238\n",
      "('book', 'book')  tienen una similaridad de:  1.0\n",
      "('book', 'i')  tienen una similaridad de:  0.1702949\n",
      "('book', 'do')  tienen una similaridad de:  -0.085621305\n",
      "('book', 'not')  tienen una similaridad de:  -0.062480308\n",
      "('book', 'like')  tienen una similaridad de:  -0.019063877\n",
      "('book', 'be')  tienen una similaridad de:  0.17937852\n",
      "('book', 'harass')  tienen una similaridad de:  0.13222475\n",
      "('book', '-PRON-')  tienen una similaridad de:  0.1309223\n",
      "('book', 'and')  tienen una similaridad de:  0.062323585\n",
      "('book', '-PRON-')  tienen una similaridad de:  0.105953805\n",
      "('book', 'will')  tienen una similaridad de:  0.05732305\n",
      "('book', 'be')  tienen una similaridad de:  0.11673942\n",
      "('book', 'ban')  tienen una similaridad de:  0.16005224\n",
      "('i', 'if')  tienen una similaridad de:  0.038858864\n",
      "('i', 'that')  tienen una similaridad de:  0.16926198\n",
      "('i', 'be')  tienen una similaridad de:  -0.15369841\n",
      "('i', 'true')  tienen una similaridad de:  0.026848767\n",
      "('i', 'then')  tienen una similaridad de:  0.0027884168\n",
      "('i', 'freedom')  tienen una similaridad de:  -0.030940415\n",
      "('i', 'of')  tienen una similaridad de:  -0.17559657\n",
      "('i', 'speech')  tienen una similaridad de:  0.19304965\n",
      "('i', 'be')  tienen una similaridad de:  -0.03632886\n",
      "('i', 'doom')  tienen una similaridad de:  0.073498875\n",
      "('i', 'harassment')  tienen una similaridad de:  0.21408865\n",
      "('i', 'be')  tienen una similaridad de:  -0.08505659\n",
      "('i', 'subjective')  tienen una similaridad de:  0.012661456\n",
      "('i', 'now')  tienen una similaridad de:  -0.01142908\n",
      "('i', 'i')  tienen una similaridad de:  1.0\n",
      "('i', 'can')  tienen una similaridad de:  -0.101407416\n",
      "('i', 'claim')  tienen una similaridad de:  -0.04536694\n",
      "('i', 'that')  tienen una similaridad de:  -0.19984314\n",
      "('i', 'a')  tienen una similaridad de:  0.07141876\n",
      "('i', 'book')  tienen una similaridad de:  0.1702949\n",
      "('i', 'i')  tienen una similaridad de:  1.0\n",
      "('i', 'do')  tienen una similaridad de:  -0.08110069\n",
      "('i', 'not')  tienen una similaridad de:  -0.0069889976\n",
      "('i', 'like')  tienen una similaridad de:  0.028432244\n",
      "('i', 'be')  tienen una similaridad de:  -0.08085165\n",
      "('i', 'harass')  tienen una similaridad de:  0.22191827\n",
      "('i', '-PRON-')  tienen una similaridad de:  0.033241473\n",
      "('i', 'and')  tienen una similaridad de:  0.03028409\n",
      "('i', '-PRON-')  tienen una similaridad de:  0.12482051\n",
      "('i', 'will')  tienen una similaridad de:  0.092607394\n",
      "('i', 'be')  tienen una similaridad de:  -0.102807075\n",
      "('i', 'ban')  tienen una similaridad de:  0.050028775\n",
      "('do', 'if')  tienen una similaridad de:  -0.014009035\n",
      "('do', 'that')  tienen una similaridad de:  -0.07103283\n",
      "('do', 'be')  tienen una similaridad de:  0.30577746\n",
      "('do', 'true')  tienen una similaridad de:  -0.09037773\n",
      "('do', 'then')  tienen una similaridad de:  -0.0703937\n",
      "('do', 'freedom')  tienen una similaridad de:  -0.070169464\n",
      "('do', 'of')  tienen una similaridad de:  -0.17687495\n",
      "('do', 'speech')  tienen una similaridad de:  -0.14396872\n",
      "('do', 'be')  tienen una similaridad de:  0.34109887\n",
      "('do', 'doom')  tienen una similaridad de:  0.08618101\n",
      "('do', 'harassment')  tienen una similaridad de:  0.13169387\n",
      "('do', 'be')  tienen una similaridad de:  0.37104824\n",
      "('do', 'subjective')  tienen una similaridad de:  0.034752134\n",
      "('do', 'now')  tienen una similaridad de:  -0.19482802\n",
      "('do', 'i')  tienen una similaridad de:  -0.038980722\n",
      "('do', 'can')  tienen una similaridad de:  0.39770728\n",
      "('do', 'claim')  tienen una similaridad de:  0.3011573\n",
      "('do', 'that')  tienen una similaridad de:  -0.18365099\n",
      "('do', 'a')  tienen una similaridad de:  -0.0017918864\n",
      "('do', 'book')  tienen una similaridad de:  -0.085621305\n",
      "('do', 'i')  tienen una similaridad de:  -0.08110069\n",
      "('do', 'do')  tienen una similaridad de:  1.0\n",
      "('do', 'not')  tienen una similaridad de:  -0.011198837\n",
      "('do', 'like')  tienen una similaridad de:  0.23393857\n",
      "('do', 'be')  tienen una similaridad de:  0.3181973\n",
      "('do', 'harass')  tienen una similaridad de:  0.07052467\n",
      "('do', '-PRON-')  tienen una similaridad de:  0.02584831\n",
      "('do', 'and')  tienen una similaridad de:  -0.007589759\n",
      "('do', '-PRON-')  tienen una similaridad de:  0.00018818978\n",
      "('do', 'will')  tienen una similaridad de:  0.23698066\n",
      "('do', 'be')  tienen una similaridad de:  0.21802525\n",
      "('do', 'ban')  tienen una similaridad de:  0.11223072\n",
      "('not', 'if')  tienen una similaridad de:  0.113111004\n",
      "('not', 'that')  tienen una similaridad de:  0.07628366\n",
      "('not', 'be')  tienen una similaridad de:  0.0057815607\n",
      "('not', 'true')  tienen una similaridad de:  0.12669988\n",
      "('not', 'then')  tienen una similaridad de:  0.3563262\n",
      "('not', 'freedom')  tienen una similaridad de:  0.19315526\n",
      "('not', 'of')  tienen una similaridad de:  0.123001516\n",
      "('not', 'speech')  tienen una similaridad de:  -0.16771367\n",
      "('not', 'be')  tienen una similaridad de:  -0.048101697\n",
      "('not', 'doom')  tienen una similaridad de:  0.04837996\n",
      "('not', 'harassment')  tienen una similaridad de:  0.059987493\n",
      "('not', 'be')  tienen una similaridad de:  0.09304366\n",
      "('not', 'subjective')  tienen una similaridad de:  0.26799315\n",
      "('not', 'now')  tienen una similaridad de:  0.31099492\n",
      "('not', 'i')  tienen una similaridad de:  0.0050362446\n",
      "('not', 'can')  tienen una similaridad de:  0.20074034\n",
      "('not', 'claim')  tienen una similaridad de:  0.060607333\n",
      "('not', 'that')  tienen una similaridad de:  0.0461737\n",
      "('not', 'a')  tienen una similaridad de:  0.01307925\n",
      "('not', 'book')  tienen una similaridad de:  -0.062480308\n",
      "('not', 'i')  tienen una similaridad de:  -0.0069889976\n",
      "('not', 'do')  tienen una similaridad de:  -0.011198837\n",
      "('not', 'not')  tienen una similaridad de:  1.0\n",
      "('not', 'like')  tienen una similaridad de:  0.2885329\n",
      "('not', 'be')  tienen una similaridad de:  0.0017412931\n",
      "('not', 'harass')  tienen una similaridad de:  0.024687216\n",
      "('not', '-PRON-')  tienen una similaridad de:  0.07215957\n",
      "('not', 'and')  tienen una similaridad de:  0.13064215\n",
      "('not', '-PRON-')  tienen una similaridad de:  0.15638983\n",
      "('not', 'will')  tienen una similaridad de:  0.30452722\n",
      "('not', 'be')  tienen una similaridad de:  0.141423\n",
      "('not', 'ban')  tienen una similaridad de:  0.003948599\n",
      "('like', 'if')  tienen una similaridad de:  0.12771402\n",
      "('like', 'that')  tienen una similaridad de:  -0.015037921\n",
      "('like', 'be')  tienen una similaridad de:  0.21437785\n",
      "('like', 'true')  tienen una similaridad de:  -0.02534264\n",
      "('like', 'then')  tienen una similaridad de:  0.15804093\n",
      "('like', 'freedom')  tienen una similaridad de:  -0.13261476\n",
      "('like', 'of')  tienen una similaridad de:  0.17814507\n",
      "('like', 'speech')  tienen una similaridad de:  -0.04499965\n",
      "('like', 'be')  tienen una similaridad de:  0.2550264\n",
      "('like', 'doom')  tienen una similaridad de:  -0.01561831\n",
      "('like', 'harassment')  tienen una similaridad de:  0.13507783\n",
      "('like', 'be')  tienen una similaridad de:  0.32754084\n",
      "('like', 'subjective')  tienen una similaridad de:  0.03495921\n",
      "('like', 'now')  tienen una similaridad de:  0.16088355\n",
      "('like', 'i')  tienen una similaridad de:  0.018227693\n",
      "('like', 'can')  tienen una similaridad de:  0.023268502\n",
      "('like', 'claim')  tienen una similaridad de:  0.3795749\n",
      "('like', 'that')  tienen una similaridad de:  0.07356866\n",
      "('like', 'a')  tienen una similaridad de:  -0.060565405\n",
      "('like', 'book')  tienen una similaridad de:  -0.019063877\n",
      "('like', 'i')  tienen una similaridad de:  0.028432244\n",
      "('like', 'do')  tienen una similaridad de:  0.23393857\n",
      "('like', 'not')  tienen una similaridad de:  0.2885329\n",
      "('like', 'like')  tienen una similaridad de:  1.0\n",
      "('like', 'be')  tienen una similaridad de:  0.37212557\n",
      "('like', 'harass')  tienen una similaridad de:  -0.088969804\n",
      "('like', '-PRON-')  tienen una similaridad de:  -0.049252383\n",
      "('like', 'and')  tienen una similaridad de:  -0.080476254\n",
      "('like', '-PRON-')  tienen una similaridad de:  0.19501244\n",
      "('like', 'will')  tienen una similaridad de:  0.20750879\n",
      "('like', 'be')  tienen una similaridad de:  0.34507865\n",
      "('like', 'ban')  tienen una similaridad de:  0.18711106\n",
      "('be', 'if')  tienen una similaridad de:  0.09429676\n",
      "('be', 'that')  tienen una similaridad de:  -0.13437758\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'true')  tienen una similaridad de:  -0.185968\n",
      "('be', 'then')  tienen una similaridad de:  -0.09022575\n",
      "('be', 'freedom')  tienen una similaridad de:  -0.104788095\n",
      "('be', 'of')  tienen una similaridad de:  0.05216647\n",
      "('be', 'speech')  tienen una similaridad de:  -0.021731675\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'doom')  tienen una similaridad de:  0.19680713\n",
      "('be', 'harassment')  tienen una similaridad de:  -0.020937202\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'subjective')  tienen una similaridad de:  -0.00050386175\n",
      "('be', 'now')  tienen una similaridad de:  -0.027228924\n",
      "('be', 'i')  tienen una similaridad de:  -0.02606488\n",
      "('be', 'can')  tienen una similaridad de:  0.11779962\n",
      "('be', 'claim')  tienen una similaridad de:  0.43294317\n",
      "('be', 'that')  tienen una similaridad de:  0.06418628\n",
      "('be', 'a')  tienen una similaridad de:  -0.065256216\n",
      "('be', 'book')  tienen una similaridad de:  0.17937852\n",
      "('be', 'i')  tienen una similaridad de:  -0.08085165\n",
      "('be', 'do')  tienen una similaridad de:  0.3181973\n",
      "('be', 'not')  tienen una similaridad de:  0.0017412931\n",
      "('be', 'like')  tienen una similaridad de:  0.37212557\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'harass')  tienen una similaridad de:  0.10398628\n",
      "('be', '-PRON-')  tienen una similaridad de:  -0.15049574\n",
      "('be', 'and')  tienen una similaridad de:  -0.092672\n",
      "('be', '-PRON-')  tienen una similaridad de:  0.035185665\n",
      "('be', 'will')  tienen una similaridad de:  0.23493928\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'ban')  tienen una similaridad de:  0.2226944\n",
      "('harass', 'if')  tienen una similaridad de:  0.0896189\n",
      "('harass', 'that')  tienen una similaridad de:  0.043887842\n",
      "('harass', 'be')  tienen una similaridad de:  0.09118501\n",
      "('harass', 'true')  tienen una similaridad de:  0.372222\n",
      "('harass', 'then')  tienen una similaridad de:  0.15703674\n",
      "('harass', 'freedom')  tienen una similaridad de:  0.09289969\n",
      "('harass', 'of')  tienen una similaridad de:  -0.15080507\n",
      "('harass', 'speech')  tienen una similaridad de:  0.15042073\n",
      "('harass', 'be')  tienen una similaridad de:  0.024570214\n",
      "('harass', 'doom')  tienen una similaridad de:  0.47482824\n",
      "('harass', 'harassment')  tienen una similaridad de:  0.33837056\n",
      "('harass', 'be')  tienen una similaridad de:  -0.07855498\n",
      "('harass', 'subjective')  tienen una similaridad de:  0.3240076\n",
      "('harass', 'now')  tienen una similaridad de:  -0.0043993904\n",
      "('harass', 'i')  tienen una similaridad de:  0.16800489\n",
      "('harass', 'can')  tienen una similaridad de:  -0.07136258\n",
      "('harass', 'claim')  tienen una similaridad de:  0.0055162045\n",
      "('harass', 'that')  tienen una similaridad de:  0.032204293\n",
      "('harass', 'a')  tienen una similaridad de:  0.1448032\n",
      "('harass', 'book')  tienen una similaridad de:  0.13222475\n",
      "('harass', 'i')  tienen una similaridad de:  0.22191827\n",
      "('harass', 'do')  tienen una similaridad de:  0.07052467\n",
      "('harass', 'not')  tienen una similaridad de:  0.024687216\n",
      "('harass', 'like')  tienen una similaridad de:  -0.088969804\n",
      "('harass', 'be')  tienen una similaridad de:  0.10398628\n",
      "('harass', 'harass')  tienen una similaridad de:  1.0\n",
      "('harass', '-PRON-')  tienen una similaridad de:  0.16347066\n",
      "('harass', 'and')  tienen una similaridad de:  0.15130351\n",
      "('harass', '-PRON-')  tienen una similaridad de:  0.040896587\n",
      "('harass', 'will')  tienen una similaridad de:  0.036108814\n",
      "('harass', 'be')  tienen una similaridad de:  0.059408735\n",
      "('harass', 'ban')  tienen una similaridad de:  0.36235937\n",
      "('-PRON-', 'if')  tienen una similaridad de:  -0.07211381\n",
      "('-PRON-', 'that')  tienen una similaridad de:  -0.17550263\n",
      "('-PRON-', 'be')  tienen una similaridad de:  -0.10795711\n",
      "('-PRON-', 'true')  tienen una similaridad de:  0.2998248\n",
      "('-PRON-', 'then')  tienen una similaridad de:  -0.0103002805\n",
      "('-PRON-', 'freedom')  tienen una similaridad de:  0.19423473\n",
      "('-PRON-', 'of')  tienen una similaridad de:  0.02508841\n",
      "('-PRON-', 'speech')  tienen una similaridad de:  0.020731803\n",
      "('-PRON-', 'be')  tienen una similaridad de:  -0.07031376\n",
      "('-PRON-', 'doom')  tienen una similaridad de:  0.12207218\n",
      "('-PRON-', 'harassment')  tienen una similaridad de:  0.14433128\n",
      "('-PRON-', 'be')  tienen una similaridad de:  -0.12786719\n",
      "('-PRON-', 'subjective')  tienen una similaridad de:  0.10850234\n",
      "('-PRON-', 'now')  tienen una similaridad de:  0.026854811\n",
      "('-PRON-', 'i')  tienen una similaridad de:  0.02809503\n",
      "('-PRON-', 'can')  tienen una similaridad de:  -0.045706403\n",
      "('-PRON-', 'claim')  tienen una similaridad de:  -0.050733943\n",
      "('-PRON-', 'that')  tienen una similaridad de:  -0.08055038\n",
      "('-PRON-', 'a')  tienen una similaridad de:  -0.24018882\n",
      "('-PRON-', 'book')  tienen una similaridad de:  0.1309223\n",
      "('-PRON-', 'i')  tienen una similaridad de:  0.033241473\n",
      "('-PRON-', 'do')  tienen una similaridad de:  0.02584831\n",
      "('-PRON-', 'not')  tienen una similaridad de:  0.07215957\n",
      "('-PRON-', 'like')  tienen una similaridad de:  -0.049252383\n",
      "('-PRON-', 'be')  tienen una similaridad de:  -0.15049574\n",
      "('-PRON-', 'harass')  tienen una similaridad de:  0.16347066\n",
      "('-PRON-', '-PRON-')  tienen una similaridad de:  1.0\n",
      "('-PRON-', 'and')  tienen una similaridad de:  0.09369636\n",
      "('-PRON-', '-PRON-')  tienen una similaridad de:  1.0\n",
      "('-PRON-', 'will')  tienen una similaridad de:  -0.10930102\n",
      "('-PRON-', 'be')  tienen una similaridad de:  -0.14458586\n",
      "('-PRON-', 'ban')  tienen una similaridad de:  0.10599287\n",
      "('and', 'if')  tienen una similaridad de:  0.16564919\n",
      "('and', 'that')  tienen una similaridad de:  0.073183544\n",
      "('and', 'be')  tienen una similaridad de:  -0.07484178\n",
      "('and', 'true')  tienen una similaridad de:  0.08959572\n",
      "('and', 'then')  tienen una similaridad de:  0.044648837\n",
      "('and', 'freedom')  tienen una similaridad de:  0.15449566\n",
      "('and', 'of')  tienen una similaridad de:  0.2639736\n",
      "('and', 'speech')  tienen una similaridad de:  0.09804313\n",
      "('and', 'be')  tienen una similaridad de:  -0.19067602\n",
      "('and', 'doom')  tienen una similaridad de:  0.17953219\n",
      "('and', 'harassment')  tienen una similaridad de:  0.032956637\n",
      "('and', 'be')  tienen una similaridad de:  -0.076059446\n",
      "('and', 'subjective')  tienen una similaridad de:  0.10653235\n",
      "('and', 'now')  tienen una similaridad de:  0.024909774\n",
      "('and', 'i')  tienen una similaridad de:  -0.04851899\n",
      "('and', 'can')  tienen una similaridad de:  0.019247292\n",
      "('and', 'claim')  tienen una similaridad de:  -0.055968575\n",
      "('and', 'that')  tienen una similaridad de:  0.091797374\n",
      "('and', 'a')  tienen una similaridad de:  -0.11193985\n",
      "('and', 'book')  tienen una similaridad de:  0.062323585\n",
      "('and', 'i')  tienen una similaridad de:  0.03028409\n",
      "('and', 'do')  tienen una similaridad de:  -0.007589759\n",
      "('and', 'not')  tienen una similaridad de:  0.13064215\n",
      "('and', 'like')  tienen una similaridad de:  -0.080476254\n",
      "('and', 'be')  tienen una similaridad de:  -0.092672\n",
      "('and', 'harass')  tienen una similaridad de:  0.15130351\n",
      "('and', '-PRON-')  tienen una similaridad de:  0.09369636\n",
      "('and', 'and')  tienen una similaridad de:  1.0\n",
      "('and', '-PRON-')  tienen una similaridad de:  0.121965565\n",
      "('and', 'will')  tienen una similaridad de:  0.24389687\n",
      "('and', 'be')  tienen una similaridad de:  -0.04554336\n",
      "('and', 'ban')  tienen una similaridad de:  0.061657812\n",
      "('-PRON-', 'if')  tienen una similaridad de:  -0.1430247\n",
      "('-PRON-', 'that')  tienen una similaridad de:  -0.15073125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-PRON-', 'be')  tienen una similaridad de:  0.03856206\n",
      "('-PRON-', 'true')  tienen una similaridad de:  0.13159776\n",
      "('-PRON-', 'then')  tienen una similaridad de:  -0.10865013\n",
      "('-PRON-', 'freedom')  tienen una similaridad de:  0.11533956\n",
      "('-PRON-', 'of')  tienen una similaridad de:  0.11098407\n",
      "('-PRON-', 'speech')  tienen una similaridad de:  0.14770074\n",
      "('-PRON-', 'be')  tienen una similaridad de:  0.12685783\n",
      "('-PRON-', 'doom')  tienen una similaridad de:  0.08218168\n",
      "('-PRON-', 'harassment')  tienen una similaridad de:  0.16172187\n",
      "('-PRON-', 'be')  tienen una similaridad de:  0.013898109\n",
      "('-PRON-', 'subjective')  tienen una similaridad de:  -0.022013795\n",
      "('-PRON-', 'now')  tienen una similaridad de:  -0.045272898\n",
      "('-PRON-', 'i')  tienen una similaridad de:  0.1303855\n",
      "('-PRON-', 'can')  tienen una similaridad de:  0.06492424\n",
      "('-PRON-', 'claim')  tienen una similaridad de:  0.075684525\n",
      "('-PRON-', 'that')  tienen una similaridad de:  -0.11603953\n",
      "('-PRON-', 'a')  tienen una similaridad de:  -0.11754079\n",
      "('-PRON-', 'book')  tienen una similaridad de:  0.105953805\n",
      "('-PRON-', 'i')  tienen una similaridad de:  0.12482051\n",
      "('-PRON-', 'do')  tienen una similaridad de:  0.00018818978\n",
      "('-PRON-', 'not')  tienen una similaridad de:  0.15638983\n",
      "('-PRON-', 'like')  tienen una similaridad de:  0.19501244\n",
      "('-PRON-', 'be')  tienen una similaridad de:  0.035185665\n",
      "('-PRON-', 'harass')  tienen una similaridad de:  0.040896587\n",
      "('-PRON-', '-PRON-')  tienen una similaridad de:  1.0\n",
      "('-PRON-', 'and')  tienen una similaridad de:  0.121965565\n",
      "('-PRON-', '-PRON-')  tienen una similaridad de:  1.0\n",
      "('-PRON-', 'will')  tienen una similaridad de:  0.18862756\n",
      "('-PRON-', 'be')  tienen una similaridad de:  0.05407579\n",
      "('-PRON-', 'ban')  tienen una similaridad de:  0.21067087\n",
      "('will', 'if')  tienen una similaridad de:  -0.024915839\n",
      "('will', 'that')  tienen una similaridad de:  0.013508681\n",
      "('will', 'be')  tienen una similaridad de:  0.16057017\n",
      "('will', 'true')  tienen una similaridad de:  -0.16283208\n",
      "('will', 'then')  tienen una similaridad de:  0.036357436\n",
      "('will', 'freedom')  tienen una similaridad de:  0.16823898\n",
      "('will', 'of')  tienen una similaridad de:  0.0559058\n",
      "('will', 'speech')  tienen una similaridad de:  0.2419773\n",
      "('will', 'be')  tienen una similaridad de:  0.21848492\n",
      "('will', 'doom')  tienen una similaridad de:  0.04037502\n",
      "('will', 'harassment')  tienen una similaridad de:  0.19031131\n",
      "('will', 'be')  tienen una similaridad de:  0.23828572\n",
      "('will', 'subjective')  tienen una similaridad de:  -0.04231798\n",
      "('will', 'now')  tienen una similaridad de:  -0.15202692\n",
      "('will', 'i')  tienen una similaridad de:  0.022782143\n",
      "('will', 'can')  tienen una similaridad de:  0.62892777\n",
      "('will', 'claim')  tienen una similaridad de:  -0.017036472\n",
      "('will', 'that')  tienen una similaridad de:  -0.06659386\n",
      "('will', 'a')  tienen una similaridad de:  -0.0005832484\n",
      "('will', 'book')  tienen una similaridad de:  0.05732305\n",
      "('will', 'i')  tienen una similaridad de:  0.092607394\n",
      "('will', 'do')  tienen una similaridad de:  0.23698066\n",
      "('will', 'not')  tienen una similaridad de:  0.30452722\n",
      "('will', 'like')  tienen una similaridad de:  0.20750879\n",
      "('will', 'be')  tienen una similaridad de:  0.23493928\n",
      "('will', 'harass')  tienen una similaridad de:  0.036108814\n",
      "('will', '-PRON-')  tienen una similaridad de:  -0.10930102\n",
      "('will', 'and')  tienen una similaridad de:  0.24389687\n",
      "('will', '-PRON-')  tienen una similaridad de:  0.18862756\n",
      "('will', 'will')  tienen una similaridad de:  1.0\n",
      "('will', 'be')  tienen una similaridad de:  0.32220116\n",
      "('will', 'ban')  tienen una similaridad de:  0.11302327\n",
      "('be', 'if')  tienen una similaridad de:  0.03364901\n",
      "('be', 'that')  tienen una similaridad de:  -0.11361566\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'true')  tienen una similaridad de:  -0.11924976\n",
      "('be', 'then')  tienen una similaridad de:  -0.14181118\n",
      "('be', 'freedom')  tienen una similaridad de:  -0.05310833\n",
      "('be', 'of')  tienen una similaridad de:  0.08824294\n",
      "('be', 'speech')  tienen una similaridad de:  0.0060365633\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'doom')  tienen una similaridad de:  0.056893345\n",
      "('be', 'harassment')  tienen una similaridad de:  -0.04838609\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'subjective')  tienen una similaridad de:  0.011695626\n",
      "('be', 'now')  tienen una similaridad de:  -0.16434018\n",
      "('be', 'i')  tienen una similaridad de:  -0.116867065\n",
      "('be', 'can')  tienen una similaridad de:  0.14479291\n",
      "('be', 'claim')  tienen una similaridad de:  0.56608325\n",
      "('be', 'that')  tienen una similaridad de:  0.10469144\n",
      "('be', 'a')  tienen una similaridad de:  -0.14793186\n",
      "('be', 'book')  tienen una similaridad de:  0.11673942\n",
      "('be', 'i')  tienen una similaridad de:  -0.102807075\n",
      "('be', 'do')  tienen una similaridad de:  0.21802525\n",
      "('be', 'not')  tienen una similaridad de:  0.141423\n",
      "('be', 'like')  tienen una similaridad de:  0.34507865\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'harass')  tienen una similaridad de:  0.059408735\n",
      "('be', '-PRON-')  tienen una similaridad de:  -0.14458586\n",
      "('be', 'and')  tienen una similaridad de:  -0.04554336\n",
      "('be', '-PRON-')  tienen una similaridad de:  0.05407579\n",
      "('be', 'will')  tienen una similaridad de:  0.32220116\n",
      "('be', 'be')  tienen una similaridad de:  1.0\n",
      "('be', 'ban')  tienen una similaridad de:  0.3480779\n",
      "('ban', 'if')  tienen una similaridad de:  0.029008508\n",
      "('ban', 'that')  tienen una similaridad de:  -0.086382255\n",
      "('ban', 'be')  tienen una similaridad de:  0.0027359168\n",
      "('ban', 'true')  tienen una similaridad de:  0.17012255\n",
      "('ban', 'then')  tienen una similaridad de:  0.11599501\n",
      "('ban', 'freedom')  tienen una similaridad de:  0.25645125\n",
      "('ban', 'of')  tienen una similaridad de:  0.111512855\n",
      "('ban', 'speech')  tienen una similaridad de:  0.093238786\n",
      "('ban', 'be')  tienen una similaridad de:  0.20472221\n",
      "('ban', 'doom')  tienen una similaridad de:  0.4599081\n",
      "('ban', 'harassment')  tienen una similaridad de:  0.3938702\n",
      "('ban', 'be')  tienen una similaridad de:  0.12887473\n",
      "('ban', 'subjective')  tienen una similaridad de:  0.16307719\n",
      "('ban', 'now')  tienen una similaridad de:  -0.008658049\n",
      "('ban', 'i')  tienen una similaridad de:  0.04437892\n",
      "('ban', 'can')  tienen una similaridad de:  0.012643506\n",
      "('ban', 'claim')  tienen una similaridad de:  0.3890207\n",
      "('ban', 'that')  tienen una similaridad de:  0.055136975\n",
      "('ban', 'a')  tienen una similaridad de:  0.15632208\n",
      "('ban', 'book')  tienen una similaridad de:  0.16005224\n",
      "('ban', 'i')  tienen una similaridad de:  0.050028775\n",
      "('ban', 'do')  tienen una similaridad de:  0.11223072\n",
      "('ban', 'not')  tienen una similaridad de:  0.003948599\n",
      "('ban', 'like')  tienen una similaridad de:  0.18711106\n",
      "('ban', 'be')  tienen una similaridad de:  0.2226944\n",
      "('ban', 'harass')  tienen una similaridad de:  0.36235937\n",
      "('ban', '-PRON-')  tienen una similaridad de:  0.10599287\n",
      "('ban', 'and')  tienen una similaridad de:  0.061657812\n",
      "('ban', '-PRON-')  tienen una similaridad de:  0.21067087\n",
      "('ban', 'will')  tienen una similaridad de:  0.11302327\n",
      "('ban', 'be')  tienen una similaridad de:  0.3480779\n",
      "('ban', 'ban')  tienen una similaridad de:  1.0\n"
     ]
    }
   ],
   "source": [
    "df1_simil = simil(df1_nm['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de entidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasif(dataframe):\n",
    "    dataframe = dataframe.rename(columns={'class':'clasif','id':'id', 'text':'text'})\n",
    "    dataframe = pd.DataFrame(dataframe, columns = ['clasif', 'id', 'text'])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = clasif(df1)\n",
    "df_2 = clasif(df2)\n",
    "df_3 = clasif(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clasif</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notsarc</td>\n",
       "      <td>1</td>\n",
       "      <td>(if, that, be, true, then, freedom, of, speech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>notsarc</td>\n",
       "      <td>2</td>\n",
       "      <td>(neener, neener, be, -PRON-, time, to, go, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>notsarc</td>\n",
       "      <td>3</td>\n",
       "      <td>(just, like, the, plastic, gun, fear, the, arm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notsarc</td>\n",
       "      <td>4</td>\n",
       "      <td>(so, geology, be, a, religion, because, -PRON-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notsarc</td>\n",
       "      <td>5</td>\n",
       "      <td>(well, do, monty, mark, that, up, as, -PRON-, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>sarc</td>\n",
       "      <td>6516</td>\n",
       "      <td>(depend, on, when, the, baby, bird, die,    , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>sarc</td>\n",
       "      <td>6517</td>\n",
       "      <td>(ok, sheesh, to, clarify, woman, who, be, not,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>sarc</td>\n",
       "      <td>6518</td>\n",
       "      <td>(so,    , eh,    , how, s, this, sound,    , w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>sarc</td>\n",
       "      <td>6519</td>\n",
       "      <td>(i, think, -PRON-, should, put, to, a, vote, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>sarc</td>\n",
       "      <td>6520</td>\n",
       "      <td>(-PRON-, have, a, blob, of, tissue, in, -PRON-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6520 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clasif    id                                               text\n",
       "0     notsarc     1  (if, that, be, true, then, freedom, of, speech...\n",
       "1     notsarc     2  (neener, neener, be, -PRON-, time, to, go, in,...\n",
       "2     notsarc     3  (just, like, the, plastic, gun, fear, the, arm...\n",
       "3     notsarc     4  (so, geology, be, a, religion, because, -PRON-...\n",
       "4     notsarc     5  (well, do, monty, mark, that, up, as, -PRON-, ...\n",
       "...       ...   ...                                                ...\n",
       "6515     sarc  6516  (depend, on, when, the, baby, bird, die,    , ...\n",
       "6516     sarc  6517  (ok, sheesh, to, clarify, woman, who, be, not,...\n",
       "6517     sarc  6518  (so,    , eh,    , how, s, this, sound,    , w...\n",
       "6518     sarc  6519  (i, think, -PRON-, should, put, to, a, vote, t...\n",
       "6519     sarc  6520  (-PRON-, have, a, blob, of, tissue, in, -PRON-...\n",
       "\n",
       "[6520 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcasmo = df_1[df_1.clasif == \"sarc\"]\n",
    "notsarcasmo = df_1[df_1.clasif == \"notsarc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_recognition(docs):\n",
    "    entity = []\n",
    "    for doc in docs:\n",
    "        for ent in doc.ents:\n",
    "             entity.append(ent.label_)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_sarcasmo_1 = entity_recognition(sarcasmo['text'])\n",
    "count_sarc_1 = word_counter(ent_sarcasmo_1)\n",
    "nuevo_1 = pd.DataFrame.from_dict(count_sarc_1, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ORDINAL</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVENT</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDINAL</th>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSON</th>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORP</th>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAW</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANGUAGE</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUANTITY</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONEY</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCT</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAC</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORK_OF_ART</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "ORDINAL      111\n",
       "EVENT          2\n",
       "CARDINAL     519\n",
       "PERSON       538\n",
       "NORP         366\n",
       "ORG          294\n",
       "GPE          300\n",
       "DATE         312\n",
       "LAW           31\n",
       "LOC           65\n",
       "LANGUAGE      18\n",
       "QUANTITY      29\n",
       "MONEY         39\n",
       "PRODUCT       18\n",
       "TIME          30\n",
       "FAC            5\n",
       "PERCENT        4\n",
       "WORK_OF_ART    6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuevo_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_notsarcasmo_1 = entity_recognition(notsarcasmo['text'])\n",
    "count_notsarc_1 = word_counter(ent_notsarcasmo_1)\n",
    "nuevo_2 = pd.DataFrame.from_dict(count_notsarc_1, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = entity_recognition(df1_nm['text'])\n",
    "count_total = word_counter(total)\n",
    "nuevo_3 = pd.DataFrame.from_dict(count_total, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frec_sarc_1</th>\n",
       "      <th>Frec_notsarc_2</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ORDINAL</th>\n",
       "      <td>111</td>\n",
       "      <td>227</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVENT</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDINAL</th>\n",
       "      <td>519</td>\n",
       "      <td>933</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSON</th>\n",
       "      <td>538</td>\n",
       "      <td>476</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORP</th>\n",
       "      <td>366</td>\n",
       "      <td>393</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>294</td>\n",
       "      <td>375</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>300</td>\n",
       "      <td>403</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>312</td>\n",
       "      <td>547</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAW</th>\n",
       "      <td>31</td>\n",
       "      <td>64</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANGUAGE</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUANTITY</th>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONEY</th>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCT</th>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAC</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORK_OF_ART</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Frec_sarc_1  Frec_notsarc_2  Total\n",
       "ORDINAL              111             227    338\n",
       "EVENT                  2              14     16\n",
       "CARDINAL             519             933   1452\n",
       "PERSON               538             476   1014\n",
       "NORP                 366             393    759\n",
       "ORG                  294             375    669\n",
       "GPE                  300             403    703\n",
       "DATE                 312             547    859\n",
       "LAW                   31              64     95\n",
       "LOC                   65             112    177\n",
       "LANGUAGE              18               9     27\n",
       "QUANTITY              29              27     56\n",
       "MONEY                 39              33     72\n",
       "PRODUCT               18              34     52\n",
       "TIME                  30              48     78\n",
       "FAC                    5              13     18\n",
       "PERCENT                4               3      7\n",
       "WORK_OF_ART            6               8     14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se comparan las frecuencias de entidades entre los comentarios sarcásticos y no sarcásticos\n",
    "concatenado = pd.concat([nuevo_1, nuevo_2, nuevo_3], axis=1)\n",
    "concatenado.columns = ['Frec_sarc_1', 'Frec_notsarc_2', 'Total']\n",
    "concatenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nota final\n",
    "El heatmap y el corte o filtro de palabras fueron realizados en el práctico número 1, por eso no los hemos realizado aquí."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
