{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Aprendizaje Automático y Supervisado\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the library thingies\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import (\n",
        "    TfidfVectorizer,\n",
        "    CountVectorizer,\n",
        "    TfidfTransformer,\n",
        ")\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "\n",
        "# import the utils thingies\n",
        "from utils.concat_dfs import get_df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the language thingies\n",
        "nltk.download('stopwords')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data thingies and concatenate them\n",
        "df = get_df([\n",
        "    \"../dataframes/GEN-sarc-notsarc.csv\",\n",
        "    \"../dataframes/RQ-sarc-notsarc.csv\",\n",
        "    \"../dataframes/HYP-sarc-notsarc.csv\",\n",
        "])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the tf-idf counter thingy of the data thingies\n",
        "MIN_NGRAM = 1\n",
        "MAX_NGRAM = 3\n",
        "\n",
        "MIN_DF = 5\n",
        "MAX_DF = 0.2\n",
        "\n",
        "corpus = df['text'].apply(lambda x: np.str_(x))\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(MIN_NGRAM, MAX_NGRAM),\n",
        "    min_df=MIN_DF,\n",
        "    max_df=MAX_DF,\n",
        "    stop_words=stopwords.words('english'),\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(corpus)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the vectorizer thingy in train and test thingies\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df[\"class\"])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('lg_clf', LogisticRegression()),\n",
        "])\n",
        "\n",
        "parameters = {\n",
        "    'vect__max_df': (0.3, 0.5, 0.75, 1.0),\n",
        "    'vect__max_features': (None, 5000, 10000, 50000),\n",
        "    'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    # 'tfidf__norm': ('l1', 'l2'),\n",
        "    'lg_clf__max_iter': (100,),\n",
        "    'lg_clf__penalty': ('l2', 'elasticnet'),\n",
        "    # 'clf__max_iter': (10, 50, 80),\n",
        "    # 'svm_clf__max_iter': (20,),\n",
        "    # 'svm_clf__alpha': (0.00001, 0.000001),\n",
        "    # 'svm_clf__penalty': ('l2', 'elasticnet'),\n",
        "    # 'clf__max_iter': (10, 50, 80),\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(df[\"text\"], df[\"class\"])\n",
        "grid_search.best_estimator_.get_params()\n",
        "grid_search.best_estimator_.get_params()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train a classifier thingy\n",
        "lg_clf = LogisticRegression()\n",
        "lg_clf.fit(X_train, y_train)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict sarcasm thingies using the classifier thingy\n",
        "y_pred = lg_clf.predict(X_test)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print metrics of the prediction thingy\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train a classifier thingy\n",
        "svm_clf = svm.SVC()\n",
        "svm_clf.fit(X_train, y_train)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict sarcasm thingies using the classifier thingy\n",
        "y_pred = svm_clf.predict(X_test)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print metrics of the prediction thingy\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La medida 'Accuracy' es una forma de medir la frecuencia con la que el algoritmo\n",
        "clasifica un punto de datos correctamente. En un modelo, se corresponde al\n",
        "número de puntos de datos predichos correctamente de todos los puntos de datos.\n",
        "En ambos modelos, obtuvimos un 'Accuracy' que supera el 70%. Esto significa que\n",
        "nuestro predictor funciona correctamente para decirnos si una frase es\n",
        "sarcástica, o no, 70 veces de 100. Creemos que es un buen numero para obtener\n",
        "como resultado, y pensamos seguir modificando parámetros para poder mejorar aún\n",
        "mas nuestros modelos.\n",
        "\n",
        "'Precision-Recall' es una medida útil del éxito de la predicción cuando las\n",
        "clases están muy desequilibradas. En la recuperación de información, 'Precision'\n",
        "es una medida de la relevancia de los resultados, mientras que 'Recall' es una \n",
        "medida de cuántos resultados verdaderamente relevantes se devuelven.\n",
        "Obtuvimos en nuestros modelos puntajes que superan el 70%. Existe entonces una\n",
        "alta recuperación y una alta precisión, donde la alta precisión se relaciona con\n",
        "una tasa baja de falsos positivos y la alta recuperación se relaciona con una\n",
        "baja tasa de falsos negativos. Los puntajes altos para ambos muestran que el\n",
        "clasificador está arrojando resultados precisos, así como también, que los\n",
        "mismos están taggeados correctamente."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/home/julieta/miniconda3/bin/python3",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}